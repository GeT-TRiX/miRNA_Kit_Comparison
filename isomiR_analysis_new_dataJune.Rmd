---
title: "isomiR_analysis"
author: "Carrie Wright"
date: "2/22/2018"
output: html_document
---

Trimming code on SRV4 /media/Backup1_/smallRNA/FullHiSeq_mismatch0/repro/samples_lanesCombined/trimmed_fastq_liberal
```{bash, eval = FALSE}
< trim_sample_list.txt parallel -P4 "/home/carrie/cutadapt -a TGGAATTCTCGGGTGCCAAGG -o $outDir/NEXT_trim1.{}.fq $inDir/NEXTFlex{}_*_R1_001.fastq.gz"

< NEXTtrim_sample_list.txt parallel -P4 "/home/carrie/cutadapt -u 4 -o NEXT_trim2.{}.fq NEXT_trim1.{}.fq"

< NEXTtrim_sample_list.txt parallel -P4 "/home/carrie/cutadapt -m 16 -u -4 -o NEXT_trimmed.{}.fq NEXT_trim2.{}.fq"

< trim_sample_list.txt parallel -P4 "/home/carrie/cutadapt -m 16 -u 3 -a AAAAAAAAAA -o  $outDir/Clontech_trimmed.{}.fq $inDir/Clontech{}_*_R1_001.fastq.gz"

< trim_sample_list.txt parallel -P4 "/home/carrie/cutadapt -m 16 -a TGGAATTCTCGGGTGCCAAGG -o $outDir/Illumina_trimmed.{}.fq $inDir/Illumina{}_*_R1_001.fastq.gz"

< trim_sample_list.txt parallel -P4 "/home/carrie/cutadapt -m 16 -a AGATCGGAAGAGCACACGTCT -o $outDir/NEB_trimmed.{}.fq $inDir/NEB{}_*_R1_001.fastq.gz"
```

UMI Script for isomiRs on SRV4

```{bash, eval =FALSE}
mkdir UMI_duplicates_rem

inDir=/media/Backup1_/smallRNA/FullHiSeq_mismatch0/repro/samples_lanesCombined/trimmed_fastq_liberal
outDir=/media/Backup1_/smallRNA/FullHiSeq_mismatch0/repro/samples_lanesCombined/trimmed_fastq_liberal/UMI_duplicates_rem

#reading every 4th line starting with line 2, get first 4 characters of sequence
awk2='NR%4==2'
< list_for_UMI.txt parallel -P4 "cat $inDir/NEXT_trim1.{}.fq | awk '$awk2' | cut -d' ' -f2 | cut -c1-4 > $outDir/first4_{}.txt"

#reading every 4th line starting with line 2, get last 4 characters of sequence
< list_for_UMI.txt parallel -P4 "cat $inDir/NEXT_trim1.{}.fq | awk '$awk2' | sed 's/^.*\(.\{4\}\)/\1/' > $outDir/last4_{}.txt"

#pasting first UMI 4 nuc. with last UMI 4 nuc.
< list_for_UMI.txt parallel -P4 "paste -d'\0' $outDir/first4_{}.txt $outDir/last4_{}.txt > $outDir/UMI_{}.txt"

#quadruple UMIs
< list_for_UMI.txt parallel -P4 "awk '{for(i=0;i<4;i++)print}' $outDir/UMI_{}.txt >$outDir/quad_UMI_{}.txt"

# add an "_" to the front of every UMI line
awk3='$0="_"$0'
< list_for_UMI.txt parallel -P4 "awk '$awk3'  $outDir/quad_UMI_{}.txt > $outDir/final_UMI_{}.txt"

# add the UMI to the fastq file identifier line
awk4='{getline p<f} (NR%4==1){$1=$1" "$2;$2=p}1'
< list_for_UMI.txt parallel -P4 "awk '$awk4' OFS= f=$outDir/final_UMI_{}.txt $inDir/NEXT_trim1.{}.fq > $outDir/NEXT_{}_UMItools_R1.fq"

#remove reads from fastq with Ns in the UMI:
#< list_for_UMI.txt parallel -P4 "sed -e '/_N\|_.*N/,+3d' $outDir/NEXT_{}_UMItools_R1.fq > $outDir/NEXT_Ns_rem_{}_UMItools_R1.fq"

#remove random 4 base pair seqs that make up the UMI from the fastq read sequence line:
< list_for_UMI.txt parallel -P4 "/home/carrie/cutadapt -u 4 -o $outDir/trim2_{}_Ns_kept_forUMI_tools.fq $outDir/NEXT_{}_UMItools_R1.fq"

< list_for_UMI.txt parallel -P4 "/home/carrie/cutadapt -m 16 -u  -4 -o $outDir/trimmed_{}_Ns_kept_forUMI_tools.fq $outDir/trim2_{}_Ns_kept_forUMI_tools.fq"


#remove space form the identifier of the fastq
< list_for_UMI.txt parallel -P4 "sed 's/ /-/' $outDir/trimmed_{}_Ns_kept_forUMI_tools.fq > $outDir/nospace_trimmed_{}_Ns_kept_forUMI_tools.fq"

#bowtie alignment
< list_for_UMI.txt parallel -P3 "/usr/bin/bowtie /media/DATA/carrie/miRge/miRge-master/miRge.seqLibs/human/mirna --fullref  -S $outDir/nospace_trimmed_{}_Ns_kept_forUMI_tools.fq $outDir/NEXT_{}_Ns_kept_readyforUMItools.sam"

#convert to bams
< list_for_UMI.txt parallel -P3 "samtools view -bS -o $outDir/NEXT_{}_Ns_kept_readyforUMItools.bam $outDir/NEXT_{}_Ns_kept_readyforUMItools.sam"

#index and sort bams
< list_for_UMI.txt parallel -P3 "samtools sort $outDir/NEXT_{}_Ns_kept_readyforUMItools.bam $outDir/NEXT_{}_Ns_kept_readyforUMItools_sorted"
< list_for_UMI.txt parallel -P3 "samtools index $outDir/NEXT_{}_Ns_kept_readyforUMItools_sorted.bam"

#UMItools
< list_for_UMI.txt parallel -P3 "umi_tools dedup --method directional -I $outDir/NEXT_{}_Ns_kept_readyforUMItools_sorted.bam -S $outDir/directional_deduped_Ns_kept_{}_UMItools.bam"


#convert deduped bam files to fastq files
<list_for_UMI.txt parallel -P3 "bam2fastx -q -Q -A -o $outDir/directional_dedupped_Ns_kept_{}_TEST.fq $outDir/directional_deduped_Ns_kept_{}_UMItools.bam"
```


miRge command on SRV2
```{bash, eval = FALSE}
#located here: carrie@srv02:~/miRge/miRge-master/isomiR_study_2_20_18
<<<<<<< HEAD
perl miRge.pl --species human --diff-isomirs --phred64 --bowtie /usr/bin/bowtie --CPU 10 --SampleFiles Clontech_trimmed.1.fq,Clontech_trimmed.2.fq,Clontech_trimmed.3.fq,Clontech_trimmed.4.fq,Clontech_trimmed.5.fq,Clontech_trimmed.6.fq,Clontech_trimmed.7.fq,Clontech_trimmed.8.fq,Clontech_trimmed.9.fq,Clontech_trimmed.10.fq,Clontech_trimmed.11.fq,Clontech_trimmed.12.fq,Clontech_trimmed.13.fq,Clontech_trimmed.14.fq,Clontech_trimmed.15.fq,Clontech_trimmed.16.fq,Clontech_trimmed.17.fq,Clontech_trimmed.18.fq,Clontech_trimmed.1_acc.fq,Clontech_trimmed.2_acc.fq,Clontech_trimmed.3_acc.fq,Illumina_trimmed.1.fq,Illumina_trimmed.2.fq,Illumina_trimmed.3.fq,Illumina_trimmed.4.fq,Illumina_trimmed.5.fq,Illumina_trimmed.6.fq,Illumina_trimmed.7.fq,Illumina_trimmed.8.fq,Illumina_trimmed.9.fq,Illumina_trimmed.1_acc.fq,Illumina_trimmed.2_acc.fq,Illumina_trimmed.3_acc.fq,NEB_trimmed.1.fq,NEB_trimmed.2.fq,NEB_trimmed.3.fq,NEB_trimmed.4.fq,NEB_trimmed.5.fq,NEB_trimmed.6.fq,NEB_trimmed.7.fq,NEB_trimmed.8.fq,NEB_trimmed.9.fq,NEB_trimmed.10.fq,NEB_trimmed.11.fq,NEB_trimmed.12.fq,NEB_trimmed.1_acc.fq,NEB_trimmed.2_acc.fq,NEB_trimmed.3_acc.fq,NEXT_trimmed.1.fq,NEXT_trimmed.2.fq,NEXT_trimmed.3.fq,NEXT_trimmed.4.fq,NEXT_trimmed.5.fq,NEXT_trimmed.6.fq,NEXT_trimmed.7.fq,NEXT_trimmed.8.fq,NEXT_trimmed.9.fq,NEXT_trimmed.10.fq,NEXT_trimmed.11.fq,NEXT_trimmed.12.fq,NEXT_trimmed.13.fq,NEXT_trimmed.14.fq,NEXT_trimmed.15.fq,NEXT_trimmed.16.fq,NEXT_trimmed.17.fq,NEXT_trimmed.18.fq,NEXT_trimmed.1_acc.fq,NEXT_trimmed.2_acc.fq,NEXT_trimmed.3_acc.fq,directional_dedupped_Ns_kept_1_TEST.fq,directional_dedupped_Ns_kept_2_TEST.fq,directional_dedupped_Ns_kept_3_TEST.fq,directional_dedupped_Ns_kept_4_TEST.fq,directional_dedupped_Ns_kept_5_TEST.fq,directional_dedupped_Ns_kept_6_TEST.fq,directional_dedupped_Ns_kept_7_TEST.fq,directional_dedupped_Ns_kept_8_TEST.fq,directional_dedupped_Ns_kept_9_TEST.fq,directional_dedupped_Ns_kept_10_TEST.fq,directional_dedupped_Ns_kept_11_TEST.fq,directional_dedupped_Ns_kept_12_TEST.fq,directional_dedupped_Ns_kept_13_TEST.fq,directional_dedupped_Ns_kept_14_TEST.fq,directional_dedupped_Ns_kept_15_TEST.fq,directional_dedupped_Ns_kept_16_TEST.fq,directional_dedupped_Ns_kept_17_TEST.fq,directional_dedupped_Ns_kept_18_TEST.fq,directional_dedupped_Ns_kept_1_acc_TEST.fq,directional_dedupped_Ns_kept_2_acc_TEST.fq,directional_dedupped_Ns_kept_3_acc_TEST.fq


=======
perl miRge.pl --species human --diff-isomirs --phred64 --bowtie /usr/bin/bowtie --CPU 10 --SampleFiles Clontech_trimmed.1.fq,Clontech_trimmed.2.fq,Clontech_trimmed.3.fq,Clontech_trimmed.4.fq,Clontech_trimmed.5.fq,Clontech_trimmed.6.fq,Clontech_trimmed.7.fq,Clontech_trimmed.8.fq,Clontech_trimmed.9.fq,Clontech_trimmed.10.fq,Clontech_trimmed.11.fq,Clontech_trimmed.12.fq,Clontech_trimmed.13.fq,Clontech_trimmed.14.fq,Clontech_trimmed.15.fq,Clontech_trimmed.16.fq,Clontech_trimmed.17.fq,Clontech_trimmed.18.fq,Clontech_trimmed.1_acc.fq,Clontech_trimmed.2_acc.fq,Clontech_trimmed.3_acc.fq,Illumina_trimmed.1.fq,Illumina_trimmed.2.fq,Illumina_trimmed.3.fq,Illumina_trimmed.4.fq,Illumina_trimmed.5.fq,Illumina_trimmed.6.fq,Illumina_trimmed.7.fq,Illumina_trimmed.8.fq,Illumina_trimmed.9.fq,Illumina_trimmed.1_acc.fq,Illumina_trimmed.2_acc.fq,Illumina_trimmed.3_acc.fq,NEB_trimmed.1.fq,NEB_trimmed.2.fq,NEB_trimmed.3.fq,NEB_trimmed.4.fq,NEB_trimmed.5.fq,NEB_trimmed.6.fq,NEB_trimmed.7.fq,NEB_trimmed.8.fq,NEB_trimmed.9.fq,NEB_trimmed.10.fq,NEB_trimmed.11.fq,NEB_trimmed.12.fq,NEB_trimmed.1_acc.fq,NEB_trimmed.2_acc.fq,NEB_trimmed.3_acc.fq,NEXT_trimmed.1.fq,NEXT_trimmed.1.fq,NEXT_trimmed.2.fq,NEXT_trimmed.3.fq,NEXT_trimmed.4.fq,NEXT_trimmed.5.fq,NEXT_trimmed.6.fq,NEXT_trimmed.7.fq,NEXT_trimmed.8.fq,NEXT_trimmed.9.fq,NEXT_trimmed.10.fq,NEXT_trimmed.11.fq,NEXT_trimmed.12.fq,NEXT_trimmed.13.fq,NEXT_trimmed.14.fq,NEXT_trimmed.15.fq,NEXT_trimmed.16.fq,NEXT_trimmed.17.fq,NEXT_trimmed.18.fq,NEXT_trimmed.1_acc.fq,NEXT_trimmed.2_acc.fq,NEXT_trimmed.3_acc.fq,directional_dedupped_Ns_kept_1_TEST.fq,directional_dedupped_Ns_kept_1_TEST.fq,directional_dedupped_Ns_kept_1_TEST.fq,directional_dedupped_Ns_kept_1_TEST.fq,directional_dedupped_Ns_kept_1_TEST.fq,directional_dedupped_Ns_kept_1_TEST.fq,directional_dedupped_Ns_kept_1_TEST.fq,directional_dedupped_Ns_kept_1_TEST.fq,directional_dedupped_Ns_kept_1_TEST.fq,directional_dedupped_Ns_kept_2_TEST.fq,directional_dedupped_Ns_kept_3_TEST.fq,directional_dedupped_Ns_kept_4_TEST.fq,directional_dedupped_Ns_kept_5_TEST.fq,directional_dedupped_Ns_kept_6_TEST.fq,directional_dedupped_Ns_kept_7_TEST.fq,directional_dedupped_Ns_kept_8_TEST.fq,directional_dedupped_Ns_kept_9_TEST.fq,directional_dedupped_Ns_kept_10_TEST.fq,directional_dedupped_Ns_kept_11_TEST.fq,directional_dedupped_Ns_kept_12_TEST.fq,directional_dedupped_Ns_kept_13_TEST.fq,directional_dedupped_Ns_kept_14_TEST.fq,directional_dedupped_Ns_kept_15_TEST.fq,directional_dedupped_Ns_kept_16_TEST.fq,directional_dedupped_Ns_kept_17_TEST.fq,directional_dedupped_Ns_kept_18_TEST.fq,directional_dedupped_Ns_kept_1_acc_TEST.fq,directional_dedupped_Ns_kept_2_acc_TEST.fq,directional_dedupped_Ns_kept_3_acc_TEST.fq


#redoing
perl miRge.pl --species human --diff-isomirs --phred64 --bowtie /usr/bin/bowtie --CPU 10 --SampleFiles Clontech_trimmed.1.fq,Clontech_trimmed.2.fq,Clontech_trimmed.3.fq,Clontech_trimmed.4.fq,Clontech_trimmed.5.fq,Clontech_trimmed.6.fq,Clontech_trimmed.7.fq,Clontech_trimmed.8.fq,Clontech_trimmed.9.fq,Clontech_trimmed.10.fq,Clontech_trimmed.11.fq,Clontech_trimmed.12.fq,Clontech_trimmed.13.fq,Clontech_trimmed.14.fq,Clontech_trimmed.15.fq,Clontech_trimmed.16.fq,Clontech_trimmed.17.fq,Clontech_trimmed.18.fq,Clontech_trimmed.1_acc.fq,Clontech_trimmed.2_acc.fq,Clontech_trimmed.3_acc.fq,Illumina_trimmed.1.fq,Illumina_trimmed.2.fq,Illumina_trimmed.3.fq,Illumina_trimmed.4.fq,Illumina_trimmed.5.fq,Illumina_trimmed.6.fq,Illumina_trimmed.7.fq,Illumina_trimmed.8.fq,Illumina_trimmed.9.fq,Illumina_trimmed.1_acc.fq,Illumina_trimmed.2_acc.fq,Illumina_trimmed.3_acc.fq,NEB_trimmed.1.fq,NEB_trimmed.2.fq,NEB_trimmed.3.fq,NEB_trimmed.4.fq,NEB_trimmed.5.fq,NEB_trimmed.6.fq,NEB_trimmed.7.fq,NEB_trimmed.8.fq,NEB_trimmed.9.fq,NEB_trimmed.10.fq,NEB_trimmed.11.fq,NEB_trimmed.12.fq,NEB_trimmed.1_acc.fq,NEB_trimmed.2_acc.fq,NEB_trimmed.3_acc.fq,NEXT_trimmed.1.fq,NEXT_trimmed.2.fq,NEXT_trimmed.3.fq,NEXT_trimmed.4.fq,NEXT_trimmed.5.fq,NEXT_trimmed.6.fq,NEXT_trimmed.7.fq,NEXT_trimmed.8.fq,NEXT_trimmed.9.fq,NEXT_trimmed.10.fq,NEXT_trimmed.11.fq,NEXT_trimmed.12.fq,NEXT_trimmed.13.fq,NEXT_trimmed.14.fq,NEXT_trimmed.15.fq,NEXT_trimmed.16.fq,NEXT_trimmed.17.fq,NEXT_trimmed.18.fq,NEXT_trimmed.1_acc.fq,NEXT_trimmed.2_acc.fq,NEXT_trimmed.3_acc.fq,directional_dedupped_Ns_kept_1_TEST.fq,directional_dedupped_Ns_kept_2_TEST.fq,directional_dedupped_Ns_kept_3_TEST.fq,directional_dedupped_Ns_kept_4_TEST.fq,directional_dedupped_Ns_kept_5_TEST.fq,directional_dedupped_Ns_kept_6_TEST.fq,directional_dedupped_Ns_kept_7_TEST.fq,directional_dedupped_Ns_kept_8_TEST.fq,directional_dedupped_Ns_kept_9_TEST.fq,directional_dedupped_Ns_kept_10_TEST.fq,directional_dedupped_Ns_kept_11_TEST.fq,directional_dedupped_Ns_kept_12_TEST.fq,directional_dedupped_Ns_kept_13_TEST.fq,directional_dedupped_Ns_kept_14_TEST.fq,directional_dedupped_Ns_kept_15_TEST.fq,directional_dedupped_Ns_kept_16_TEST.fq,directional_dedupped_Ns_kept_17_TEST.fq,directional_dedupped_Ns_kept_18_TEST.fq,directional_dedupped_Ns_kept_1_acc_TEST.fq,directional_dedupped_Ns_kept_2_acc_TEST.fq,directional_dedupped_Ns_kept_3_acc_TEST.fq

#redoing again


carrie@srv02:~/miRge/miRge-master$ perl miRge.pl --species human --diff-isomirs --phred64 --bowtie /usr/bin/bowtie --CPU 10 --SampleFiles Clontech_trimmed.1_acc.fq,Clontech_trimmed.2_acc.fq,Clontech_trimmed.3_acc.fq,Illumina_trimmed.1_acc.fq,Illumina_trimmed.2_acc.fq,Illumina_trimmed.3_acc.fq,NEB_trimmed.1_acc.fq,NEB_trimmed.2_acc.fq,NEB_trimmed.3_acc.fq,NEXT_trimmed.1_acc.fq,NEXT_trimmed.2_acc.fq,NEXT_trimmed.3_acc.fq,directional_deduped_int_trim_Ns_rem_1_acc.fq,directional_deduped_int_trim_Ns_rem_2_acc.fq,directional_deduped_int_trim_Ns_rem_3_acc.fq,Clontech_trimmed.1.fq,Clontech_trimmed.2.fq,Clontech_trimmed.3.fq,Clontech_trimmed.4.fq,Clontech_trimmed.5.fq,Clontech_trimmed.6.fq,Clontech_trimmed.7.fq,Clontech_trimmed.8.fq,Clontech_trimmed.9.fq,Clontech_trimmed.10.fq,Clontech_trimmed.11.fq,Clontech_trimmed.12.fq,Clontech_trimmed.13.fq,Clontech_trimmed.14.fq,Clontech_trimmed.15.fq,Clontech_trimmed.16.fq,Clontech_trimmed.17.fq,Clontech_trimmed.18.fq,Illumina_trimmed.1.fq,Illumina_trimmed.2.fq,Illumina_trimmed.3.fq,Illumina_trimmed.4.fq,Illumina_trimmed.5.fq,Illumina_trimmed.6.fq,Illumina_trimmed.7.fq,Illumina_trimmed.8.fq,Illumina_trimmed.9.fq,NEB_trimmed.1.fq,NEB_trimmed.2.fq,NEB_trimmed.3.fq,NEB_trimmed.4.fq,NEB_trimmed.5.fq,NEB_trimmed.6.fq,NEB_trimmed.7.fq,NEB_trimmed.8.fq,NEB_trimmed.9.fq,NEB_trimmed.10.fq,NEB_trimmed.11.fq,NEB_trimmed.12.fq,NEXT_trimmed.1.fq,NEXT_trimmed.2.fq,NEXT_trimmed.3.fq,NEXT_trimmed.4.fq,NEXT_trimmed.5.fq,NEXT_trimmed.6.fq,NEXT_trimmed.7.fq,NEXT_trimmed.8.fq,NEXT_trimmed.9.fq,NEXT_trimmed.10.fq,NEXT_trimmed.11.fq,NEXT_trimmed.12.fq,NEXT_trimmed.13.fq,NEXT_trimmed.14.fq,NEXT_trimmed.15.fq,NEXT_trimmed.16.fq,NEXT_trimmed.17.fq,NEXT_trimmed.18.fq,directional_deduped_int_trim_Ns_rem_1.fq,directional_deduped_int_trim_Ns_rem_2.fq,directional_deduped_int_trim_Ns_rem_3.fq,directional_deduped_int_trim_Ns_rem_4.fq,directional_deduped_int_trim_Ns_rem_5.fq,directional_deduped_int_trim_Ns_rem_6.fq,directional_deduped_int_trim_Ns_rem_7.fq,directional_deduped_int_trim_Ns_rem_8.fq,directional_deduped_int_trim_Ns_rem_9.fq,directional_deduped_int_trim_Ns_rem_10.fq,directional_deduped_int_trim_Ns_rem_11.fq,directional_deduped_int_trim_Ns_rem_12.fq,directional_deduped_int_trim_Ns_rem_13.fq,directional_deduped_int_trim_Ns_rem_14.fq,directional_deduped_int_trim_Ns_rem_15.fq,directional_deduped_int_trim_Ns_rem_16.fq,directional_deduped_int_trim_Ns_rem_17.fq,directional_deduped_int_trim_Ns_rem_18.fq
```

#Generate count data
```{r}
library(here)

isomiR_Counts <-read.table(here("Complete_data/IsomiR_data/isomirs.csv"), header = TRUE, sep = ",", row.names = NULL)
colnames(isomiR_Counts)<-colnames(isomiR_Counts)[-(grep("row.names", colnames(isomiR_Counts)))]# shift everything to right
isomiR_Counts<-as.data.frame(isomiR_Counts)
# Entropy <- isomiR_Counts$Entropy
# 
Pheno<- read.table(here("Complete_data/Pheno.txt"), header = T)
Pheno <- Pheno[6:length(Pheno$File),]
Pheno$Kit <- gsub("Five_double","Fivepercent", Pheno$Kit)
Pheno$Kit <- gsub("NEXTflex_deduped","Deduped", Pheno$Kit)
Counts <-isomiR_Counts[3:(length(isomiR_Counts) -2)]
 Counts <-Counts[6:length(Counts)]# to remove extra files.....
# 
 colnames(Counts)<-gsub("directional_dedupped|directional_deduped", "Deduped", colnames(Counts))
 colnames(Counts)<-gsub("NEXT_", "NEXTflex_", colnames(Counts))
 annotation <-isomiR_Counts[1:2]

save(Counts, file =here("Complete_data/IsomiR_data/Counts.rda"))
#save(Entropy, file = here("Complete_data/IsomiR_data/Entropy.rda"))
save(annotation, file = here("Complete_data/IsomiR_data/annotation.rda"))
#save(Pheno, file = here("IsomiR_data/Pheno.rda"))
```

Need to convert from RPM to raw counts

```{r}
library(here)
iso_RPM <-Counts

library(XML)
report_url<-here("Complete_data/report.html")# from miRge
urltxt <- readLines(report_url)
report<-readHTMLTable(doc = report_url, header = TRUE) #need to read every third line
report <- report [-length(report)]
report <-as.data.frame(report)
report <-report[1:9]
report <-report[seq(from =1, to = nrow(report), by = 5),]# remove extra empty lines
report <- report[6:length(report$NULL.File.name.s.),]#remove extra files
total_reads <-as.numeric(as.character(report$NULL.Total.Input.Reads))# all isomir and canoncial reads
total_miRNA<-vapply(strsplit(as.character(report$NULL.All.miRNA.Reads...Filtered.miRNA.Reads),"/"),`[`, 2, FUN.VALUE=character(1))#need to use the filtered number of miRNA reads
total_miRNA<-gsub("[[:blank:]]", "", total_miRNA)
total_miRNA<-as.numeric(as.character(total_miRNA))

rep.row<-function(x,n){
   matrix(rep(x,each=n),nrow=n)
}
dimensions<-dim(iso_RPM)
Totalmatrix<-rep.row((total_miRNA/1000000), dimensions[1])#width of isoRPM2

iso_Raw<- (iso_RPM)*(as.numeric(Totalmatrix))
iso_Raw <- round(iso_Raw,digits = 0)
save(iso_Raw, file = here("Complete_data/IsomiR_data/Iso_raw.rda"))
save(total_miRNA, report, file = here("Complete_data/IsomiR_data/total_miRNA.rda"))
```

#load processed data
```{eval = FALSE}
library(here)
#load(here("IsomiR_data/Entropy.rda"))
load(here("Complete_data/IsomiR_data/Iso_raw.rda"))
load(here("Complete_data/IsomiR_data/annotation.rda"))
load(here("Complete_data/Pheno.txt"))
load(here("Complete_data/IsomiR_data//total_miRNA.rda"))
```

Normalization... I think I only need to do by kit...
###DESeq2
```{r, eval=FALSE, warning=FALSE, message=FALSE, echo =FALSE}
library(DESeq2)
library(reshape2)
library(ggplot2)
norm_miR <-list()
Pheno$Kit<- factor(Pheno$Kit)
dds<-DESeqDataSetFromMatrix(countData = iso_Raw, colData = Pheno, design = ~ Kit)
dds <- estimateSizeFactors(dds)
norm_miR<-data.frame(counts(dds, normalized = TRUE))
save(norm_miR, file = here("IsomiR_data/norm_miR.rda"))
```

Could do fancier normalization
```{r, eval = FALSE, echo = FALSE}
Pheno$startingAmt<-paste0("starting_amt_", Pheno$startingAmt)
###split the data by starting Amount
split_startingAmt <- list() 
for(i in Pheno$startingAmt) { 
  split_startingAmt[[i]] <- data.frame(iso_Raw[which(Pheno$startingAmt==i)])
}
###split the pheno by starting Amount
Pheno_Amt <- list() 
for(i in Pheno$startingAmt) { 
  Pheno_Amt[[i]] <- data.frame(Pheno[which(Pheno$startingAmt==i),])
}

# library(edgeR)
# norm_miR <-list()
# for(i in unique(Pheno$startingAmt)){
# d<-DGEList(counts = split_startingAmt[[i]], group = Pheno$Kit[which(Pheno$startingAmt==i)])
# miR_TMM_edgeR_factors <-calcNormFactors(d, method = "TMM")
# TMM <-estimateCommonDisp(miR_TMM_edgeR_factors)
# norm_miR[[i]] <-data.frame(TMM$pseudo.counts)
# }

#save(norm_miR, miR_counts, Pheno, file = here("IsomiR_16lim_data/iso_data.rda"))
```


#################################################################START HERE####################
#summarized data
```{r}
library(here)
library(ggplot2)
load(here("IsomiR_data/norm_miR.rda"))
load(here("IsomiR_data/total_miRNA.rda"))
load(here("IsomiR_data/Pheno.rda"))
norm_miRDF <-data.frame(norm_miR)
total_isomiRs_above10 <- colSums(norm_miRDF>100)
total_isomiR_reads <- colSums(norm_miRDF)
total_isomiR_reads <-data.frame(total_isomiR_reads)
total_isomiRs_above10<-data.frame(total_isomiRs_above10)
total_isomiR<-cbind(total_isomiR_reads, total_isomiRs_above10)

isomiR_DATA <- data.frame(total_isomiRs = total_isomiRs_above10$total_isomiRs_above10, Kit = Pheno$Kit, StartingAmt =Pheno$startingAmt)
isomiR_DATA$Kit <- factor(isomiR_DATA$Kit,levels = c("Clontech", "Illumina", "NEB", "NEXTflex", "Deduped", "Fivepercent"), ordered = TRUE)

#ggplot(data =isomiR_DATA, aes(x = Kit, y = total_isomiRs, fill = Kit)) +geom_boxplot()+facet_grid(.~StartingAmt)
#ggplot(data =isomiR_DATA, aes(x = Kit, y = total_isomiRs, fill = Kit)) +geom_boxplot()+facet_grid(StartingAmt~.) + geom_jitter(aes(color = Kit))
#ggplot(data =isomiR_DATA, aes(x = StartingAmt, y = total_isomiRs, fill = Kit)) +geom_point(aes(x = StartingAmt, y = total_isomiRs))+facet_grid(.~Kit) + geom_jitter(aes(color = Kit))

ggplot(data = isomiR_DATA, aes(x = StartingAmt, y = total_isomiRs, group = StartingAmt)) + geom_jitter(aes(color = Kit))+ geom_boxplot(aes(fill = Kit)) + facet_grid(.~Kit) + scale_x_continuous(breaks=unique(isomiR_DATA$StartingAmt)) + theme(legend.position = "none", axis.text.x = element_text(size =14, angle = 60, hjust = 1), axis.text.y = element_text(size =14, hjust = 1), axis.title=element_text(size = 20), plot.title = element_text(size = 20)) + labs(y = " Number of Uniquely Detected miRNA Sequences", title = "isomiRNA Detection across kits") +geom_smooth(method = "loess", se=TRUE, color="black", aes(group=1))  



#total_reads <-as.numeric(as.character(report$NULL.Total.Input.Reads))


#summarized_Data <- data.frame(total_miRNA=(as.data.frame(total_miRNA)), totalreads =report$NULL.Total.Input.Reads)
#summarized_Data$percentmiRNA <- (as.numeric(summarized_Data$total_miRNA)/as.numeric(as.character(summarized_Data$totalreads)))*100
#summarized_Data$Kit <- Pheno$Kit



```
#stats
Is there a relationship between starting amount and the number detected
```{r}
library(broom)
det_mod <-lm(isomiR_DATA$total_isomiRs ~ isomiR_DATA$StartingAmt)
summary(det_mod)
det_mod <-lm(isomiR_DATA$total_isomiRs ~isomiR_DATA$Kit)
summary(det_mod)

split_kit <-list()
for(i in isomiR_DATA$Kit) { 
  split_kit[[i]] <- data.frame(isomiR_DATA[which(Det_data$Kit==i),])
} 
#Det_data$Starting_Amount<-factor(Det_data$Starting_Amount)
 run_model <-function(x){(lm(x[["total_isomiRs"]]~x[["StartingAmt"]]))}
model_stats<-lapply(split_kit,run_model)
model_summary<-lapply(model_stats, summary)
lapply(model_summary, glance)# only Deduped and Fivepercent are significant

model_summary$Deduped
split_amt <-list()
for(i in unique(as.character(isomiR_DATA$StartingAmt))) { 
  split_amt[[i]] <- data.frame(isomiR_DATA[which(isomiR_DATA$StartingAmt==i),])
} 
 run_model <-function(x){(lm(x[["total_isomiRs"]]~x[["Kit"]]))}
model_stats<-lapply(split_amt,run_model)
model_summary<-lapply(model_stats, summary)
lapply(model_summary, glance)# all significant


t.test(split_kit$Clontech$miRNA, split_kit$NEXTflex$miRNA)

t.test(split_amt$`100`$miRNA[grep("Clontech",split_amt$`100`$Kit)], split_amt$`100`$miRNA[grep("NEB", split_amt$`100`$Kit)])

Det <-t(detected)
colnames(Det)<- Pheno$Kit
#split_amt <-list()
#for(i in unique(Pheno$startingAmt)) { 
#    split_amt[[i]] <- data.frame(Det[,which(Pheno$startingAmt==i), drop = FALSE])
#    colnames(split_amt[[i]]) <- Pheno$Kit[which(Pheno$startingAmt==i)]}


```


```{r, echo = TRUE, eval=TRUE}
library(dplyr)
get_test_names <- function(data){
  test_names <<- data.frame(combn(unique(names(data)), m= 2))
}

get_test_results<- function(data,test_names) {
  tresults<<-list()
  tested_names1<<-list()
  tested_names2<<-list()
  for(i in names(test_names)){
    #tested_names[[i]]<<-(test_names[i][,1])
    Kit1<-data[grep(test_names[i][1,], names(data))]
    Kit2<-data[grep(test_names[i][2,], names(data))]
    #Kit1<-data.frame(select(data, names(data)[names(data) %in% test_names[i][1,]]))
    #Kit2<-data.frame(select(data, names(data)[names(data) %in% test_names[i][2,]]))
    tested_names1[[i]]<<-names(Kit1)
    tested_names2[[i]]<<-names(Kit2)
    # colnames(Kit1)<-c("error")
    # colnames(Kit2)<-c("error")
    tresults[[i]]<<-t.test(x=Kit1[[1]][4], y=Kit2[[1]][4], paired = FALSE) ### may have messed things up adding paired = TRUE previously had more ))
    tested_kits <<-paste0(tested_names1, "&", tested_names2)
  }
}

get_ttestStats<- function(x) {
  #print(length(test_names))
  c(t =format(x$statistic, digits = 2),
    df = format(x$parameter, digits = 0),
    p.value = format(x$p.value, scientific = TRUE, digits = 2),
    bonferroni_thresh = format(.05/length(test_names), digits = 2),
    sig = ifelse(x$p.value<(.05/length(test_names)), "yes", "no"))
}

#get_lmStats <-function(x) {
#  c(p=x$coefficients[2,4], scientific = TRUE, digits =2)
#}
```

```{r}
get_test_names(split_kit)
get_test_results(data = split_kit, test_names = test_names)
ttestStats_across<-data.frame(lapply(tresults, get_ttestStats))
colnames(ttestStats_across)<-tested_kits
ttestStats_across
```


Threshold across triplicates
```{r, eval = FALSE}
library(genefilter)
library(reshape2)
isomiR_DATA <- data.frame(total_isomiRs = total_isomiRs_above10$total_isomiRs_above10, Kit = Pheno$Kit, StartingAmt =Pheno$startingAmt)
isomiR_DATA$Kit <- factor(isomiR_DATA$Kit,levels = c("Clontech", "Illumina", "NEB", "NEXTflex", "Deduped", "Fivepercent"), ordered = TRUE)

isomiR_DATA$StartingAmt<-paste0("starting_amt_", isomiR_DATA$StartingAmt)


Pheno$startingAmt <-factor(Pheno$startingAmt)
split_kit_isoData <- list()
for(i in unique(Pheno$startingAmt)) {
  for(kit in unique(Pheno$Kit)){
  split_kit_isoData[[i]][[kit]] <- data.frame(norm_miR[which(Pheno$startingAmt == as.character(i) & Pheno$Kit == as.character(kit))])}
}

poverafun <- genefilter::pOverA(p = 1, A = 100)#at least 100 normalized reads in all samples of the set... 
ffun <- filterfun(poverafun)
genefilt_fun<- function(x){genefilter(x, ffun)}

thresh <-list()
for(amt in names(split_kit_isoData)){
thresh[[amt]]<-lapply(split_kit_isoData[[as.character(amt)]], genefilt_fun)}

test <-split_kit_isoData$`100`$Clontech[thresh$`100`$Clontech,]

split_amt_thresh <-list()
for(amt in names(split_kit_isoData)){
for(kit in names(split_kit_isoData[[amt]])){
 split_amt_thresh[[amt]][[kit]]<- split_kit_isoData[[amt]][[kit]][thresh[[amt]][[kit]],]}
}

thresh_number <- list()
for(amt in names(split_kit_isoData)){
for(kit in names(split_kit_isoData[[amt]])){
thresh_number[[amt]][[kit]]<- dim(split_kit_isoData[[amt]][[kit]][thresh[[amt]][[kit]],])[1]}
}

thresh_number <-data.frame(thresh_number)
colnames(thresh_number) <-c("100", "250", "500", "1000", "1500", "2000")
thresh_number$kit <- rownames(thresh_number)
thresh_number <-melt(thresh_number)
thresh_number$variable <-as.numeric(as.character(thresh_number$variable))
thresh_number<-thresh_number[-which(thresh_number$value =="0"),]
thresh_number$kit <- factor(thresh_number$kit,levels = c("Clontech", "Illumina", "NEB", "NEXTflex", "Deduped", "Fivepercent"))

save(thresh_number, file = here("IsomiR_data/thresh_number.rda") )
```

plot of threshold across Triplicates
```{r}
load(here("IsomiR_data/thresh_number.rda"))
ggplot(data = thresh_number, aes(x = variable, y = value, group = variable)) + geom_jitter(aes(col = kit))+ facet_grid(.~kit) + scale_x_continuous(breaks=unique(thresh_number$variable)) + theme(legend.position = "none", axis.text.x = element_text(angle = 45, hjust = 1)) + labs(y = " Number of Uniquely Detected miRNA Sequences", title = "isomiRNA Detection across kits > 10 reads in all triplicates") +geom_smooth(method = "lm", se=TRUE, color="black", aes(group=1))

```


How consistent are the results...
X1) number of identified isomirs - can see on first plot
2) identity of identified isomirs - need to use annotation this could be useful - like venn diagrams ...but could just determine percentage instead?
3) expression of identified isomirs within a kit across triplicates - this is more in depth... so maybe good just to go ahead to this??/
4) expression of identified isomirs across kits or identity of identified isomirs

```{r}

lapply(split_amt_thresh[[as.character(amt)]], var)

```
#####start here for faster analysis

```{r}
load(here("isomiR_data_extended/iso_Raw.rda"))
load(here("isomiR_data_extended/iso_anno.rda"))
Pheno<- read.table(here("IsomiR_data/IsoPheno.txt"), header = T)
identical(colnames(iso_Raw), as.character(Pheno$File))
miR_counts <- read.table(here("isomiR_data_extended/miR.Counts.csv"),header = T, sep = ",")
miR_counts <-miR_counts[-grep("fq.", colnames(miR_counts))]# to remove extra files.....
miR_counts <-miR_counts[-grep("acc", colnames(miR_counts))]# to remove second batch of 1000ng files.....
Total_counts <-miR_counts[1,]
miR_counts <-miR_counts[-1,]
miR_counts <-miR_counts[-1]
#remove second batch of 1000ng starting input
iso_Raw <- iso_Raw[-grep("acc", colnames(iso_Raw))]
Pheno <- Pheno [-grep("acc", Pheno$File),]
```


### comparison of error for each kit for given starting amount
##Split the data
```{r}

Pheno$startingAmt<-paste0("starting_amt_", Pheno$startingAmt)
###split the data by starting Amount
split_startingAmt <- list() 
for(i in Pheno$startingAmt) { 
  split_startingAmt[[i]] <- data.frame(iso_Raw[which(Pheno$startingAmt==i)])
}
###split the pheno by starting Amount
Pheno_Amt <- list() 
for(i in Pheno$startingAmt) { 
  Pheno_Amt[[i]] <- data.frame(Pheno[which(Pheno$startingAmt==i),])
}

Can_split_startingAmt <- list() 
for(i in Pheno$startingAmt) { 
  Can_split_startingAmt[[i]] <- data.frame(miR_counts[which(Pheno$startingAmt==i)])
}
```
###TMM Normalization

Normalization by kit for each starting amount - to allow tests to compare kits at a given starting amt

Later will do normalization by starting amount for each kit  individually to compare how consistent the data is between starting amounts for each kit
```{r, eval= TRUE, echo =FALSE}
#library(tweeDEseq)
#miR_1000_TMM<-data.frame(normalizeCounts(miR_1000_raw)
#dim(norm_miR_1000)
#or
library(edgeR)

norm_miR <-list()
for(i in unique(Pheno$startingAmt)){
d<-DGEList(counts = split_startingAmt[[i]], group = Pheno$Kit[which(Pheno$startingAmt==i)])
miR_TMM_edgeR_factors <-calcNormFactors(d, method = "TMM")
TMM <-estimateCommonDisp(miR_TMM_edgeR_factors)
norm_miR[[i]] <-data.frame(TMM$pseudo.counts)
}

#str(norm_miR)

Can_norm_miR <-list()
for(i in unique(Pheno$startingAmt)){
d<-DGEList(counts =Can_split_startingAmt[[i]], group = Pheno$Kit[which(Pheno$startingAmt==i)])
miR_TMM_edgeR_factors <-calcNormFactors(d, method = "TMM")
TMM <-estimateCommonDisp(miR_TMM_edgeR_factors)
Can_norm_miR[[i]] <-data.frame(TMM$pseudo.counts)
}

```

Now split normalized data by kit for each amount
```{r}

split_norm_Amt <- list() 
for(i in names(norm_miR)) {
  for(kit in unique(Pheno_Amt[[i]][3]$Kit))# take the third list from each respective amount selected from norm_miR names - the third is the kit - so for each kit in the list of kits for a given amount...
  split_norm_Amt[[i]][[kit]] <-data.frame(norm_miR[[i]][which(Pheno_Amt[[i]][3] == kit)]) # take only the values that correspond to that kit for that amount
}

Can_split_norm_Amt <- list() 
for(i in names(Can_norm_miR)) {
  for(kit in unique(Pheno_Amt[[i]][3]$Kit))# take the third list from each respective amount selected from norm_miR names - the third is the kit - so for each kit in the list of kits for a given amount...
  Can_split_norm_Amt[[i]][[kit]] <-data.frame(Can_norm_miR[[i]][which(Pheno_Amt[[i]][3] == kit)]) # take only the values that correspond to that kit for that amount
}
#str(split_norm_Amt)
```




###Filter the data across triplicates for given kit at a given amount
```{r}
###genefilter
library(genefilter)

poverafun <- genefilter::pOverA(p = 1, A = 10)#at least 100 normalized reads in all samples of the set... 
ffun <- filterfun(poverafun)
genefilt_fun<- function(x){genefilter(x, ffun)}

thresh <-list()
<<<<<<< HEAD
for(amt in names(split_norm_Amt)){
thresh[[amt]]<-lapply(split_norm_Amt[[amt]], genefilt_fun)}

Can_thresh <-list()
for(amt in names(Can_split_norm_Amt)){
Can_thresh[[amt]]<-lapply(Can_split_norm_Amt[[amt]], genefilt_fun)}
=======
for(amt in names(split_norm_Amt))
thresh[[amt]]<-lapply(split_norm_Amt[[amt]], genefilt_fun)

Can_thresh <-list()
for(amt in names(Can_split_norm_Amt))
Can_thresh[[amt]]<-lapply(Can_split_norm_Amt[[amt]], genefilt_fun)
>>>>>>> b7bb0ed04bcb3658c273201b6af02e8a95fddf50


test <-split_norm_Amt$starting_amt_1000$Clontech[thresh$starting_amt_1000$Clontech,]

split_amt_thresh <-list()
for(amt in names(split_norm_Amt)){
for(kit in names(split_norm_Amt[[amt]])){
 split_amt_thresh[[amt]][[kit]]<- split_norm_Amt[[amt]][[kit]][thresh[[amt]][[kit]],]}
}

Can_split_amt_thresh <-list()
for(amt in names(Can_split_norm_Amt)){
for(kit in names(Can_split_norm_Amt[[amt]])){
 Can_split_amt_thresh[[amt]][[kit]]<- Can_split_norm_Amt[[amt]][[kit]][Can_thresh[[amt]][[kit]],]}
}
```

#detected miRNAs
```{r}
head(iso_anno[rownames(split_amt_thresh$starting_amt_100$Clontech),])
get_miRNAs <- function(x) {rownames(as.data.frame(x))}
miRNA_det_100<-lapply(split_amt_thresh$starting_amt_100,get_miRNAs)
lengths<-lapply(miRNA_det_100, length)
lengths<- paste0(lengths, "\n")
names(miRNA_det_100) <-paste0(names(miRNA_det_100), "\n")
names(miRNA_det_100) <-paste0(names(miRNA_det_100), lengths)

miRNA_det_250<-lapply(split_amt_thresh$starting_amt_250,get_miRNAs)
lengths<-lapply(miRNA_det_250, length)
names(miRNA_det_250) <-paste0(names(miRNA_det_250), "\n")
names(miRNA_det_250) <-paste0(names(miRNA_det_250), lengths)

miRNA_det_500<-lapply(split_amt_thresh$starting_amt_500,get_miRNAs)
lengths<-lapply(miRNA_det_500, length)
names(miRNA_det_500) <-paste0(names(miRNA_det_500), "\n")
names(miRNA_det_500) <-paste0(names(miRNA_det_500), lengths)

miRNA_det_1000<-lapply(split_amt_thresh$starting_amt_1000,get_miRNAs)
lengths<-lapply(miRNA_det_1000, length)
names(miRNA_det_1000) <-paste0(names(miRNA_det_1000), "\n")
names(miRNA_det_1000) <-paste0(names(miRNA_det_1000), lengths)

miRNA_det_1500<-lapply(split_amt_thresh$starting_amt_1500,get_miRNAs)
lengths<-lapply(miRNA_det_1500, length)
names(miRNA_det_1500) <-paste0(names(miRNA_det_1500), "\n")
names(miRNA_det_1500) <-paste0(names(miRNA_det_1500), lengths)

miRNA_det_2000<-lapply(split_amt_thresh$starting_amt_2000,get_miRNAs)
lengths<-lapply(miRNA_det_2000, length)
names(miRNA_det_2000) <-paste0(names(miRNA_det_2000), "\n")
names(miRNA_det_2000) <-paste0(names(miRNA_det_2000), lengths)
```

#detected miRNAs Can
```{r}
Can_miRNA_det_100<-lapply(Can_split_amt_thresh$starting_amt_100,get_miRNAs)
lengths<-lapply(Can_miRNA_det_100, length)
lengths<- paste0(lengths, "\n")
names(Can_miRNA_det_100) <-paste0(names(Can_miRNA_det_100), "\n")
names(Can_miRNA_det_100) <-paste0(names(Can_miRNA_det_100), lengths)

Can_miRNA_det_250<-lapply(Can_split_amt_thresh$starting_amt_250,get_miRNAs)
lengths<-lapply(Can_miRNA_det_250, length)
names(Can_miRNA_det_250) <-paste0(names(Can_miRNA_det_250), "\n")
names(Can_miRNA_det_250) <-paste0(names(Can_miRNA_det_250), lengths)

Can_miRNA_det_500<-lapply(Can_split_amt_thresh$starting_amt_500,get_miRNAs)
lengths<-lapply(Can_miRNA_det_500, length)
names(Can_miRNA_det_500) <-paste0(names(Can_miRNA_det_500), "\n")
names(Can_miRNA_det_500) <-paste0(names(Can_miRNA_det_500), lengths)

Can_miRNA_det_1000<-lapply(Can_split_amt_thresh$starting_amt_1000,get_miRNAs)
lengths<-lapply(Can_miRNA_det_1000, length)
names(Can_miRNA_det_1000) <-paste0(names(Can_miRNA_det_1000), "\n")
names(Can_miRNA_det_1000) <-paste0(names(Can_miRNA_det_1000), lengths)

Can_miRNA_det_1500<-lapply(Can_split_amt_thresh$starting_amt_1500,get_miRNAs)
lengths<-lapply(Can_miRNA_det_1500, length)
names(Can_miRNA_det_1500) <-paste0(names(Can_miRNA_det_1500), "\n")
names(Can_miRNA_det_1500) <-paste0(names(Can_miRNA_det_1500), lengths)

Can_miRNA_det_2000<-lapply(Can_split_amt_thresh$starting_amt_2000,get_miRNAs)
lengths<-lapply(Can_miRNA_det_2000, length)
names(Can_miRNA_det_2000) <-paste0(names(Can_miRNA_det_2000), "\n")
names(Can_miRNA_det_2000) <-paste0(names(Can_miRNA_det_2000), lengths)
```

VennDiagram
```{r}
library(VennDiagram)
gg_color_hue <- function(n) {
  hues = seq(15, 375, length = n + 1)
  hcl(h = hues, l = 65, c = 100)[1:n]
}

n = 5
cols = gg_color_hue(n)
cols <-c(cols[1], cols[3:5])

vp_100 <- venn.diagram(miRNA_det_100, fill = c(cols), alpha = 0.5, filename = NULL, margin = 0.2, cat.dist = c(.25,.25,.15, .15))
vp_250 <- venn.diagram(miRNA_det_250, fill = c(cols), alpha = 0.5, filename = NULL, margin = 0.2, cat.dist = c(.25,.25,.15, .15))
vp_500 <- venn.diagram(miRNA_det_500, fill = c(cols), alpha = 0.5, filename = NULL, margin = 0.2, cat.dist = c(.25,.25,.15, .15))
vp_1000 <- venn.diagram(miRNA_det_500, fill = c(cols), alpha = 0.5, filename = NULL, margin = 0.2, cat.dist = c(.25,.25,.15, .15))
vp_1500 <- venn.diagram(miRNA_det_1500, fill = c(cols), alpha = 0.5, filename = NULL, margin = 0.2, cat.dist = c(.25,.25,.15, .15))
vp_2000 <- venn.diagram(miRNA_det_2000, fill = c(cols), alpha = 0.5, filename = NULL, margin = 0.2, cat.dist = c(.25,.25,.15, .15))


vp_Can100 <- venn.diagram(Can_miRNA_det_100, fill = c(cols), alpha = 0.5, filename = NULL, margin = 0.2, cat.dist = c(.25,.25,.15, .15))
vp_Can250 <- venn.diagram(Can_miRNA_det_250, fill = c(cols), alpha = 0.5, filename = NULL, margin = 0.2, cat.dist = c(.25,.25,.15, .15))
vp_Can500 <- venn.diagram(Can_miRNA_det_500, fill = c(cols), alpha = 0.5, filename = NULL, margin = 0.2, cat.dist = c(.25,.25,.15, .15))
vp_Can1000 <- venn.diagram(Can_miRNA_det_500, fill = c(cols), alpha = 0.5, filename = NULL, margin = 0.2, cat.dist = c(.25,.25,.15, .15))
vp_Can1500 <- venn.diagram(Can_miRNA_det_1500, fill = c(cols), alpha = 0.5, filename = NULL, margin = 0.2, cat.dist = c(.25,.25,.15, .15))
vp_Can2000 <- venn.diagram(Can_miRNA_det_2000, fill = c(cols), alpha = 0.5, filename = NULL, margin = 0.2, cat.dist = c(.25,.25,.15, .15))


```

grid.draw(vp_1000);


OLDER
```{r}
split_norm_Amt <- list() 
for(i in names(norm_miR)) {
  for(kit in unique(Pheno_Amt[[i]][3]))# take the third list from each respective amount selected from norm_miR names - the third is the kit - so for each kit in the list of kits for a given amount...
  split_norm_Amt[[i]][[kit]] <-data.frame(norm_miR[[i]][which(Pheno_Amt[[i]][3] == kit)]) # take only the values that correspond to that kit for that amount
}


library(genefilter)

poverafun <- genefilter::pOverA(p = 1, A = 10)#at least 100 normalized reads in all samples of the set... 
ffun <- filterfun(poverafun)
genefilt_fun<- function(x){genefilter(x, ffun)}

thresh <-list()
for(amt in names(split_norm_Amt)){
thresh[[amt]]<-lapply(split_norm_Amt[[amt]], genefilt_fun)}

test <-split_norm_Amt$starting_amt_1000$Clontech[thresh$starting_amt_1000$Clontech,]

split_amt_thresh <-list()
for(amt in names(split_norm_Amt)){
for(kit in names(split_norm_Amt[[amt]])){
 split_amt_thresh[[amt]][[kit]]<- split_norm_Amt[[amt]][[kit]][thresh[[amt]][[kit]],]}
}


#detected miRNAs

head(annotation[rownames(split_amt_thresh$starting_amt_100$Clontech),])
get_miRNAs <- function(x) {rownames(as.data.frame(x))}
miRNA_det_100<-lapply(split_amt_thresh$starting_amt_100,get_miRNAs)
lengths<-lapply(miRNA_det_100, length)
lengths<- paste0(lengths, "\n")
names(miRNA_det_100) <-paste0(names(miRNA_det_100), "\n")
names(miRNA_det_100) <-paste0(names(miRNA_det_100), lengths)

miRNA_det_250<-lapply(split_amt_thresh$starting_amt_250,get_miRNAs)
lengths<-lapply(miRNA_det_250, length)
names(miRNA_det_250) <-paste0(names(miRNA_det_250), "\n")
names(miRNA_det_250) <-paste0(names(miRNA_det_250), lengths)

miRNA_det_500<-lapply(split_amt_thresh$starting_amt_500,get_miRNAs)
lengths<-lapply(miRNA_det_500, length)
names(miRNA_det_500) <-paste0(names(miRNA_det_500), "\n")
names(miRNA_det_500) <-paste0(names(miRNA_det_500), lengths)

miRNA_det_1000<-lapply(split_amt_thresh$starting_amt_1000,get_miRNAs)
lengths<-lapply(miRNA_det_1000, length)
names(miRNA_det_1000) <-paste0(names(miRNA_det_1000), "\n")
names(miRNA_det_1000) <-paste0(names(miRNA_det_1000), lengths)

miRNA_det_1500<-lapply(split_amt_thresh$starting_amt_1500,get_miRNAs)
lengths<-lapply(miRNA_det_1500, length)
names(miRNA_det_1500) <-paste0(names(miRNA_det_1500), "\n")
names(miRNA_det_1500) <-paste0(names(miRNA_det_1500), lengths)

miRNA_det_2000<-lapply(split_amt_thresh$starting_amt_2000,get_miRNAs)
lengths<-lapply(miRNA_det_2000, length)
names(miRNA_det_2000) <-paste0(names(miRNA_det_2000), "\n")
names(miRNA_det_2000) <-paste0(names(miRNA_det_2000), lengths)

library(VennDiagram)
gg_color_hue <- function(n) {
  hues = seq(15, 375, length = n + 1)
  hcl(h = hues, l = 65, c = 100)[1:n]
}

n = 5
cols = gg_color_hue(n)
cols <-c(cols[1], cols[3:5])

vp_100 <- venn.diagram(miRNA_det_100, fill = c(cols), alpha = 0.5, filename = NULL, margin = 0.2, cat.dist = c(.25,.25,.15, .15))
vp_250 <- venn.diagram(miRNA_det_250, fill = c(cols), alpha = 0.5, filename = NULL, margin = 0.2, cat.dist = c(.25,.25,.15, .15))
vp_500 <- venn.diagram(miRNA_det_500, fill = c(cols), alpha = 0.5, filename = NULL, margin = 0.2, cat.dist = c(.25,.25,.15, .15))

cols = gg_color_hue(n)
vp_1000 <- venn.diagram(miRNA_det_1000, fill = c(cols), alpha = 0.5, filename = NULL, margin = 0.2, cat.dist = c(.25,.25,.25, .25, .35))

cols = gg_color_hue(n)
cols <-c(cols[1:2], cols[4:5])
vp_1500 <- venn.diagram(miRNA_det_1500, fill = c(cols), alpha = 0.5, filename = NULL, margin = 0.2, cat.dist = c(.25,.25,.15, .15))
vp_2000 <- venn.diagram(miRNA_det_2000, fill = c(cols), alpha = 0.5, filename = NULL, margin = 0.2, cat.dist = c(.25,.25,.15, .15))

```
grid.draw(vp_1000);




=======
>>>>>>> b7bb0ed04bcb3658c273201b6af02e8a95fddf50
```{r, eval  = FALSE}

###Will output two additional files, isomirs.csv and isomirs.samples.csv. The first file has the entropy of each isomir as compared with their canonical miRNAs - % of time noncanonical - higher number means less canonical more isomirs. The second file contains the entropy of each miRNA across all isomirs and determines the % of miRNA reads that are canonical. This is done by dividing the sum of all non-edited, but length variable miRNA reads against the sum of these reads plus all isomiR (RNA-edited) reads. This can be used to flag miRNAs that are predominately ####non-canonical isomiRs and may represent sequencing errors. For example, if a miRNA is only 5% canonical, that would be worrisome and suggest a possible misidentification.

#I believe the isomirs.csv file contains one column of entropy - the one called entropy for each isomiRNA (as compared with the canonical) and then RPMs... as the values are not whole numbers... then isomirs.samples.csv contains the % of the time that a miRNA is canonical and the entropy for each isomiRNA relatve to other isomiRs for each sample pr maybe its the percent of the time that an isomiRNA is a canonical type of isomir???meaning just length variable??


# I think Entropy in isomirs.samples.csv (but this maybe the percent canonical isomiR type) = sum of all length isomir reads / sum of all types of isomir (length and RNA-edited) reads - thus if too low this is bad... seems to range to about 50% or .5

#sounds like low entropy in the isomirs.samples.csv is bad - means mostly edited-- could be sequencing error - check canonical percentage too if it is low then probably sequencing error or maybe this meens the 

iso_RPM<-read.table(here("isomiR_data_extended/isomirs.csv"), header = T, sep = ",", row.names=NULL)
iso_RPM <-iso_RPM[-grep("fq.", colnames(iso_RPM))]# to remove extra files.....

isosamples<- read.table(here("isomiR_data_extended/isomirs.samples.csv"), header = T, sep = ",", row.names=NULL)
isosamples <-isosamples[-grep("RPM.", colnames(isosamples))]# to remove extra files.....

<<<<<<< HEAD
miR_counts <- read.table(here("isomiR_data/miR.Counts.csv"),header = T, sep = ",")
=======
miR_counts <- read.table(here("isomiR_data_extended/miR.Counts.csv"),header = T, sep = ",")
>>>>>>> b7bb0ed04bcb3658c273201b6af02e8a95fddf50
miR_counts <-miR_counts[-grep("fq.", colnames(miR_counts))]# to remove extra files.....

#fixing the columns
iso_data<-iso_RPM[1:(length(colnames(iso_RPM))-1)]
colnames(iso_data)<-colnames(iso_RPM)[2:(length(colnames(iso_RPM)))]
iso_RPM2 <- iso_data[,4:length(colnames(iso_data))-1]
iso_RPM2_anno<-iso_data[1:2]

#fixing the colnames
iso_samp<-isosamples[1:(length(colnames(isosamples))-1)]
colnames(iso_samp)<-colnames(isosamples)[2:length(colnames(isosamples))]
#getting just the raw info
index<-grep("RPM", colnames(iso_samp))
iso_samp_filt<-iso_samp[-index]
rownames(iso_samp_filt)<- iso_samp$miRNA
iso_samp_filt<-iso_samp_filt[-1]

topIsomiR_entropy <-  iso_samp_filt[grep("isomir", colnames(iso_samp_filt))]
Canonical <- iso_samp_filt[grep("Canonical", colnames(iso_samp_filt))]


###convert to raw counts... use miR_counts to get total miRNA mapped number - so the miRcounts I believe includes all sequences that allign - isomir and canonical
Total<-(miR_counts[1,])[-1] #remove miRNA column
rep.row<-function(x,n){
   matrix(rep(x,each=n),nrow=n)
}
dim(iso_RPM2)
Totalmatrix<-rep.row((Total/1000000), 4430447)#width of isoRPM2

iso_Raw<- (iso_RPM2)*(as.numeric(Totalmatrix))
#save(iso_Raw, file = here("isomiR_data_extended/iso_Raw.rda"))
iso_anno <-iso_RPM2_anno
<<<<<<< HEAD
#save(iso_anno, file = here("isomiR_data_extended/iso_anno.rda"))
=======
save(iso_anno, file = here("isomiR_data_extended/iso_anno.rda"))
>>>>>>> b7bb0ed04bcb3658c273201b6af02e8a95fddf50

##########

#save(Canonical, file = here("isomiR_data_extended/Canonicalpercent.rda"))
#save(topIsomiR_entropy, file = here("isomiR_data_extended/topIsomiR_entropy.rda"))

```


#####start here for faster analysis

```{r}
load(here("isomiR_data_extended/iso_Raw.rda"))
load(here("isomiR_data_extended/iso_anno.rda"))
Pheno<- read.table(here("IsomiR_data/IsoPheno.txt"), header = T)
identical(colnames(iso_Raw), as.character(Pheno$File))
miR_counts <- read.table(here("isomiR_data_extended/miR.Counts.csv"),header = T, sep = ",")
miR_counts <-miR_counts[-grep("fq.", colnames(miR_counts))]# to remove extra files.....
miR_counts <-miR_counts[-grep("acc", colnames(miR_counts))]# to remove second batch of 1000ng files.....
Total_counts <-miR_counts[1,]
miR_counts <-miR_counts[-1,]
miR_counts <-miR_counts[-1]
#remove second batch of 1000ng starting input
iso_Raw <- iso_Raw[-grep("acc", colnames(iso_Raw))]
Pheno <- Pheno [-grep("acc", Pheno$File),]
```


### comparison of error for each kit for given starting amount
##Split the data
```{r}

Pheno$startingAmt<-paste0("starting_amt_", Pheno$startingAmt)
###split the data by starting Amount
split_startingAmt <- list() 
for(i in Pheno$startingAmt) { 
  split_startingAmt[[i]] <- data.frame(iso_Raw[which(Pheno$startingAmt==i)])
}
###split the pheno by starting Amount
Pheno_Amt <- list() 
for(i in Pheno$startingAmt) { 
  Pheno_Amt[[i]] <- data.frame(Pheno[which(Pheno$startingAmt==i),])
}

Can_split_startingAmt <- list() 
for(i in Pheno$startingAmt) { 
  Can_split_startingAmt[[i]] <- data.frame(miR_counts[which(Pheno$startingAmt==i)])
}
```
###TMM Normalization

Normalization by kit for each starting amount - to allow tests to compare kits at a given starting amt

Later will do normalization by starting amount for each kit  individually to compare how consistent the data is between starting amounts for each kit
```{r, eval= TRUE, echo =FALSE}
#library(tweeDEseq)
#miR_1000_TMM<-data.frame(normalizeCounts(miR_1000_raw)
#dim(norm_miR_1000)
#or
library(edgeR)

norm_miR <-list()
for(i in unique(Pheno$startingAmt)){
d<-DGEList(counts = split_startingAmt[[i]], group = Pheno$Kit[which(Pheno$startingAmt==i)])
miR_TMM_edgeR_factors <-calcNormFactors(d, method = "TMM")
TMM <-estimateCommonDisp(miR_TMM_edgeR_factors)
norm_miR[[i]] <-data.frame(TMM$pseudo.counts)
}

#str(norm_miR)

Can_norm_miR <-list()
for(i in unique(Pheno$startingAmt)){
d<-DGEList(counts =Can_split_startingAmt[[i]], group = Pheno$Kit[which(Pheno$startingAmt==i)])
miR_TMM_edgeR_factors <-calcNormFactors(d, method = "TMM")
TMM <-estimateCommonDisp(miR_TMM_edgeR_factors)
Can_norm_miR[[i]] <-data.frame(TMM$pseudo.counts)
}

```

Now split normalized data by kit for each amount
```{r}

split_norm_Amt <- list() 
for(i in names(norm_miR)) {
  for(kit in unique(Pheno_Amt[[i]][3]$Kit))# take the third list from each respective amount selected from norm_miR names - the third is the kit - so for each kit in the list of kits for a given amount...
  split_norm_Amt[[i]][[kit]] <-data.frame(norm_miR[[i]][which(Pheno_Amt[[i]][3] == kit)]) # take only the values that correspond to that kit for that amount
}

Can_split_norm_Amt <- list() 
for(i in names(Can_norm_miR)) {
  for(kit in unique(Pheno_Amt[[i]][3]$Kit))# take the third list from each respective amount selected from norm_miR names - the third is the kit - so for each kit in the list of kits for a given amount...
  Can_split_norm_Amt[[i]][[kit]] <-data.frame(Can_norm_miR[[i]][which(Pheno_Amt[[i]][3] == kit)]) # take only the values that correspond to that kit for that amount
}
#str(split_norm_Amt)
```




###Filter the data across triplicates for given kit at a given amount
```{r}
###genefilter
library(genefilter)

poverafun <- genefilter::pOverA(p = 1, A = 10)#at least 100 normalized reads in all samples of the set... 
ffun <- filterfun(poverafun)
genefilt_fun<- function(x){genefilter(x, ffun)}

thresh <-list()
<<<<<<< HEAD
for(amt in names(split_norm_Amt)){
thresh[[amt]]<-lapply(split_norm_Amt[[amt]], genefilt_fun)}

Can_thresh <-list()
for(amt in names(Can_split_norm_Amt)){
Can_thresh[[amt]]<-lapply(Can_split_norm_Amt[[amt]], genefilt_fun)}
=======
for(amt in names(split_norm_Amt))
thresh[[amt]]<-lapply(split_norm_Amt[[amt]], genefilt_fun)

Can_thresh <-list()
for(amt in names(Can_split_norm_Amt))
Can_thresh[[amt]]<-lapply(Can_split_norm_Amt[[amt]], genefilt_fun)
>>>>>>> b7bb0ed04bcb3658c273201b6af02e8a95fddf50


test <-split_norm_Amt$starting_amt_1000$Clontech[thresh$starting_amt_1000$Clontech,]

split_amt_thresh <-list()
for(amt in names(split_norm_Amt)){
for(kit in names(split_norm_Amt[[amt]])){
 split_amt_thresh[[amt]][[kit]]<- split_norm_Amt[[amt]][[kit]][thresh[[amt]][[kit]],]}
}

Can_split_amt_thresh <-list()
for(amt in names(Can_split_norm_Amt)){
for(kit in names(Can_split_norm_Amt[[amt]])){
 Can_split_amt_thresh[[amt]][[kit]]<- Can_split_norm_Amt[[amt]][[kit]][Can_thresh[[amt]][[kit]],]}
}
```

#detected miRNAs
```{r}
head(iso_anno[rownames(split_amt_thresh$starting_amt_100$Clontech),])
get_miRNAs <- function(x) {rownames(as.data.frame(x))}
miRNA_det_100<-lapply(split_amt_thresh$starting_amt_100,get_miRNAs)
lengths<-lapply(miRNA_det_100, length)
lengths<- paste0(lengths, "\n")
names(miRNA_det_100) <-paste0(names(miRNA_det_100), "\n")
names(miRNA_det_100) <-paste0(names(miRNA_det_100), lengths)

miRNA_det_250<-lapply(split_amt_thresh$starting_amt_250,get_miRNAs)
lengths<-lapply(miRNA_det_250, length)
names(miRNA_det_250) <-paste0(names(miRNA_det_250), "\n")
names(miRNA_det_250) <-paste0(names(miRNA_det_250), lengths)

miRNA_det_500<-lapply(split_amt_thresh$starting_amt_500,get_miRNAs)
lengths<-lapply(miRNA_det_500, length)
names(miRNA_det_500) <-paste0(names(miRNA_det_500), "\n")
names(miRNA_det_500) <-paste0(names(miRNA_det_500), lengths)

miRNA_det_1000<-lapply(split_amt_thresh$starting_amt_1000,get_miRNAs)
lengths<-lapply(miRNA_det_1000, length)
names(miRNA_det_1000) <-paste0(names(miRNA_det_1000), "\n")
names(miRNA_det_1000) <-paste0(names(miRNA_det_1000), lengths)

miRNA_det_1500<-lapply(split_amt_thresh$starting_amt_1500,get_miRNAs)
lengths<-lapply(miRNA_det_1500, length)
names(miRNA_det_1500) <-paste0(names(miRNA_det_1500), "\n")
names(miRNA_det_1500) <-paste0(names(miRNA_det_1500), lengths)

miRNA_det_2000<-lapply(split_amt_thresh$starting_amt_2000,get_miRNAs)
lengths<-lapply(miRNA_det_2000, length)
names(miRNA_det_2000) <-paste0(names(miRNA_det_2000), "\n")
names(miRNA_det_2000) <-paste0(names(miRNA_det_2000), lengths)
```

#detected miRNAs Can
```{r}
Can_miRNA_det_100<-lapply(Can_split_amt_thresh$starting_amt_100,get_miRNAs)
lengths<-lapply(Can_miRNA_det_100, length)
lengths<- paste0(lengths, "\n")
names(Can_miRNA_det_100) <-paste0(names(Can_miRNA_det_100), "\n")
names(Can_miRNA_det_100) <-paste0(names(Can_miRNA_det_100), lengths)

Can_miRNA_det_250<-lapply(Can_split_amt_thresh$starting_amt_250,get_miRNAs)
lengths<-lapply(Can_miRNA_det_250, length)
names(Can_miRNA_det_250) <-paste0(names(Can_miRNA_det_250), "\n")
names(Can_miRNA_det_250) <-paste0(names(Can_miRNA_det_250), lengths)

Can_miRNA_det_500<-lapply(Can_split_amt_thresh$starting_amt_500,get_miRNAs)
lengths<-lapply(Can_miRNA_det_500, length)
names(Can_miRNA_det_500) <-paste0(names(Can_miRNA_det_500), "\n")
names(Can_miRNA_det_500) <-paste0(names(Can_miRNA_det_500), lengths)

Can_miRNA_det_1000<-lapply(Can_split_amt_thresh$starting_amt_1000,get_miRNAs)
lengths<-lapply(Can_miRNA_det_1000, length)
names(Can_miRNA_det_1000) <-paste0(names(Can_miRNA_det_1000), "\n")
names(Can_miRNA_det_1000) <-paste0(names(Can_miRNA_det_1000), lengths)

Can_miRNA_det_1500<-lapply(Can_split_amt_thresh$starting_amt_1500,get_miRNAs)
lengths<-lapply(Can_miRNA_det_1500, length)
names(Can_miRNA_det_1500) <-paste0(names(Can_miRNA_det_1500), "\n")
names(Can_miRNA_det_1500) <-paste0(names(Can_miRNA_det_1500), lengths)

Can_miRNA_det_2000<-lapply(Can_split_amt_thresh$starting_amt_2000,get_miRNAs)
lengths<-lapply(Can_miRNA_det_2000, length)
names(Can_miRNA_det_2000) <-paste0(names(Can_miRNA_det_2000), "\n")
names(Can_miRNA_det_2000) <-paste0(names(Can_miRNA_det_2000), lengths)
```

VennDiagram
```{r}
library(VennDiagram)
gg_color_hue <- function(n) {
  hues = seq(15, 375, length = n + 1)
  hcl(h = hues, l = 65, c = 100)[1:n]
}

n = 5
cols = gg_color_hue(n)
cols <-c(cols[1], cols[3:5])

vp_100 <- venn.diagram(miRNA_det_100, fill = c(cols), alpha = 0.5, filename = NULL, margin = 0.2, cat.dist = c(.25,.25,.15, .15))
vp_250 <- venn.diagram(miRNA_det_250, fill = c(cols), alpha = 0.5, filename = NULL, margin = 0.2, cat.dist = c(.25,.25,.15, .15))
vp_500 <- venn.diagram(miRNA_det_500, fill = c(cols), alpha = 0.5, filename = NULL, margin = 0.2, cat.dist = c(.25,.25,.15, .15))
vp_1000 <- venn.diagram(miRNA_det_500, fill = c(cols), alpha = 0.5, filename = NULL, margin = 0.2, cat.dist = c(.25,.25,.15, .15))
vp_1500 <- venn.diagram(miRNA_det_1500, fill = c(cols), alpha = 0.5, filename = NULL, margin = 0.2, cat.dist = c(.25,.25,.15, .15))
vp_2000 <- venn.diagram(miRNA_det_2000, fill = c(cols), alpha = 0.5, filename = NULL, margin = 0.2, cat.dist = c(.25,.25,.15, .15))


vp_Can100 <- venn.diagram(Can_miRNA_det_100, fill = c(cols), alpha = 0.5, filename = NULL, margin = 0.2, cat.dist = c(.25,.25,.15, .15))
vp_Can250 <- venn.diagram(Can_miRNA_det_250, fill = c(cols), alpha = 0.5, filename = NULL, margin = 0.2, cat.dist = c(.25,.25,.15, .15))
vp_Can500 <- venn.diagram(Can_miRNA_det_500, fill = c(cols), alpha = 0.5, filename = NULL, margin = 0.2, cat.dist = c(.25,.25,.15, .15))
vp_Can1000 <- venn.diagram(Can_miRNA_det_500, fill = c(cols), alpha = 0.5, filename = NULL, margin = 0.2, cat.dist = c(.25,.25,.15, .15))
vp_Can1500 <- venn.diagram(Can_miRNA_det_1500, fill = c(cols), alpha = 0.5, filename = NULL, margin = 0.2, cat.dist = c(.25,.25,.15, .15))
vp_Can2000 <- venn.diagram(Can_miRNA_det_2000, fill = c(cols), alpha = 0.5, filename = NULL, margin = 0.2, cat.dist = c(.25,.25,.15, .15))


```

grid.draw(vp_1000);


Split total miRNA reads

```{r}

Total_counts<-Total_counts[-1]
###split the total counts by amount
split_total<- list() 
for(i in Pheno$TriplicateGroup) { 
 split_total[[i]] <- rowMeans(Total_counts[which(Pheno$TriplicateGroup==i)])
}
split_total<-data.frame(split_total)
split_total_miRNA<-split_total
boxplot(split_total_miRNA)

```

report stats
```{r}
library(XML)
<<<<<<< HEAD
report_url<-here("IsomiR_data_new_incomplete/report.html")
=======
report_url<-here("isomiR_data/report.html")
>>>>>>> b7bb0ed04bcb3658c273201b6af02e8a95fddf50
urltxt <- readLines(report_url)
report<-readHTMLTable(doc = report_url, header = TRUE) #need to read every third line
report <- report [-length(report)]
report <-as.data.frame(report)
report <-report[1:9]
report <-report[seq(from =1, to = nrow(report), by = 5),]
total_reads <-as.numeric(as.character(report$NULL.Total.Input.Reads))

split_total<- list() 
for(i in Pheno$TriplicateGroup) { 
 split_total[[i]] <- mean(total_reads[which(Pheno$TriplicateGroup==i)])
}
split_total<-data.frame(split_total)
boxplot(split_total)

<<<<<<< HEAD
split_total_miRNA<- list() 
for(i in Pheno$TriplicateGroup) { 
 split_total_miRNA[[i]] <- mean(total_miRNA[which(Pheno$TriplicateGroup==i)])
}
split_total_miRNA<-data.frame(split_total_miRNA)
                        
=======

>>>>>>> b7bb0ed04bcb3658c273201b6af02e8a95fddf50
boxplot(log2(split_total))
boxplot(log2(split_total_miRNA))

total_reads_final<-t(split_total)
total_miRNA_final<-t(split_total_miRNA)
totals <-data.frame(reads =total_reads_final, miRNAreads = total_miRNA_final)
<<<<<<< HEAD
####somehow figure out how to get lengths of isomiRS so we can see if they correlate with raw read count or miRNA total count 
=======
####somehow figure out how to get lengths of isomiRS so we can see if they correlate with raw read count or miRNA total count
>>>>>>> b7bb0ed04bcb3658c273201b6af02e8a95fddf50
get_lengths <-function(x){length(rownames(x))}
lapply(split_amt_thresh$starting_amt_starting_amt_starting_amt_100, get_lengths)
split_iso<- list() 
for(i in Pheno$startingAmt) { 
  for(kit in Pheno$Kit){
 split_iso[[i]][[kit]] <- mean(split_amt_thresh[which(Pheno$startingAmt==i & Pheno$Kit == kit)])
}}
split_total<-data.frame(split_total)
boxplot(split_total)



```

























###TMM Normalization

Normalization by kit for each starting amount - to allow tests to compare kits

```{r, eval= TRUE, echo =FALSE}
library(edgeR)

norm_isomiR <-list()
d<-DGEList(counts = iso_Raw, group = Pheno$Kit)
miR_TMM_edgeR_factors <-calcNormFactors(d, method = "TMM")
TMM <-estimateCommonDisp(miR_TMM_edgeR_factors)
norm_isomiR[[i]] <-data.frame(TMM$pseudo.counts)


```

Now split normalized data by kit for each amount
```{r}

split_norm_Amt <- list() 
for(i in names(norm_miR)) {
  for(kit in unique(Pheno_Amt[[i]][3]$Kit))# take the third list from each respective amount selected from norm_miR names - the third is the kit - so for each kit in the list of kits for a given amount...
  split_norm_Amt[[i]][[kit]] <-data.frame(norm_miR[[i]][which(Pheno_Amt[[i]][3] == kit)]) # take only the values that correspond to that kit for that amount
}
#str(split_norm_Amt)
```


################Analysis starts here#########################

```{r}
library(here)
here()#should be Kit_comparison_project
#need subdirectory IsomiR_data with isomirs.csv inside
#isomiR_Counts <-read.table(here("IsomiR_data/isomirs.csv"), header = TRUE, sep = ",", row.names = NULL)
#colnames(isomiR_Counts)<-colnames(isomiR_Counts)[-(grep("row.names", colnames(isomiR_Counts)))]
#isomiR_Counts<-as.data.frame(isomiR_Counts)
#Entropy <- isomiR_Counts$Entropy
#save(isomiR_Counts, file =here("IsomiR_data/isomiR_Counts.rda"))
Pheno<- read.table(here("Pheno_repro_full_1_16_18_ns_kept.txt"), header = T)
#Counts <-isomiR_Counts[3:101]
#Counts <-Counts[-grep("fq.", colnames(Counts))]

#colnames(Counts)<-gsub("directional_dedupped|directional_deduped", "Deduped", colnames(Counts))
#colnames(Counts)<-gsub("NEXT_", "NEXTflex_", colnames(Counts))

#save(Counts, file =here("IsomiR_data/Counts.rda"))
#save(Entropy, file = here("IsomiR_data/Entropy.rda"))

Pheno<-vapply(strsplit(names(Counts),"_"), `[`, 1, FUN.VALUE=character(1))
load(here("IsomiR_data/Entropy.rda"))
load(here("IsomiR_data/Counts.rda"))
Pheno_simple <- read.table("Pheno_simple.txt", header = TRUE)

#remove 2nd batch of 1000
Counts_clean <- Counts[-grep("2", Pheno_simple$Batch),]# can't do on my laptop

```

###TMM Normalization

Normalization by kit for each starting amount - to allow tests to compare kits

```{r, eval= TRUE, echo =FALSE}
library(edgeR)

norm_isomiR <-list()
d<-DGEList(counts = Counts, group = Pheno_simple$Kit)
miR_TMM_edgeR_factors <-calcNormFactors(d, method = "TMM")
TMM <-estimateCommonDisp(miR_TMM_edgeR_factors)
norm_isomiR[[i]] <-data.frame(TMM$pseudo.counts)
}

for(i in unique(Pheno_simple$Kit)){
d<-DGEList(counts = Counts[grep(i, colnames(Counts))], group = Pheno_simple$Kit[which(Pheno_simple$Kit==i)])
miR_TMM_edgeR_factors <-calcNormFactors(d, method = "TMM")
TMM <-estimateCommonDisp(miR_TMM_edgeR_factors)
norm_isomiR[[i]] <-data.frame(TMM$pseudo.counts)
}

NEXTflex <- Counts[grep(i, colnames())]

#str(norm_isomiR)

```

Now split normalized data by kit for each amount
```{r}

split_norm_Kit <- list() 
for(i in names(norm_miR)) {
  for(kit in unique(Pheno_Amt[[i]][3]$Kit))# take the third list from each respective amount selected from norm_miR names - the third is the kit - so for each kit in the list of kits for a given amount...
  split_norm_Kit[[i]][[kit]] <-data.frame(norm_isomiR[[i]][which(Pheno_Amt[[i]][3] == kit)]) # take only the values that correspond to that kit for that amount
}
#str(split_norm_Amt)
```

results in nice format
```{r}

results<-read.csv(here("../../kit_comp_isomir_results.csv"), header = TRUE)
results <-results[1:5,]
meltedresult<-melt(results)
```
