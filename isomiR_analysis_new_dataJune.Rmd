---
title: "isomiR_analysis"
author: "Carrie Wright"
date: "2/22/2018"
output: html_document
---

Trimming code on SRV4 /media/Backup1_/smallRNA/FullHiSeq_mismatch0/repro/samples_lanesCombined/trimmed_fastq_liberal
```{bash, eval = FALSE}
< trim_sample_list.txt parallel -P4 "/home/carrie/cutadapt -a TGGAATTCTCGGGTGCCAAGG -o $outDir/NEXT_trim1.{}.fq $inDir/NEXTFlex{}_*_R1_001.fastq.gz"

< NEXTtrim_sample_list.txt parallel -P4 "/home/carrie/cutadapt -u 4 -o NEXT_trim2.{}.fq NEXT_trim1.{}.fq"

< NEXTtrim_sample_list.txt parallel -P4 "/home/carrie/cutadapt -m 16 -u -4 -o NEXT_trimmed.{}.fq NEXT_trim2.{}.fq"

< trim_sample_list.txt parallel -P4 "/home/carrie/cutadapt -m 16 -u 3 -a AAAAAAAAAA -o  $outDir/Clontech_trimmed.{}.fq $inDir/Clontech{}_*_R1_001.fastq.gz"

< trim_sample_list.txt parallel -P4 "/home/carrie/cutadapt -m 16 -a TGGAATTCTCGGGTGCCAAGG -o $outDir/Illumina_trimmed.{}.fq $inDir/Illumina{}_*_R1_001.fastq.gz"

< trim_sample_list.txt parallel -P4 "/home/carrie/cutadapt -m 16 -a AGATCGGAAGAGCACACGTCT -o $outDir/NEB_trimmed.{}.fq $inDir/NEB{}_*_R1_001.fastq.gz"
```

UMI Script for isomiRs on SRV4

```{bash, eval =FALSE}
mkdir UMI_duplicates_rem

inDir=/media/Backup1_/smallRNA/FullHiSeq_mismatch0/repro/samples_lanesCombined/trimmed_fastq_liberal
outDir=/media/Backup1_/smallRNA/FullHiSeq_mismatch0/repro/samples_lanesCombined/trimmed_fastq_liberal/UMI_duplicates_rem

#reading every 4th line starting with line 2, get first 4 characters of sequence
awk2='NR%4==2'
< list_for_UMI.txt parallel -P4 "cat $inDir/NEXT_trim1.{}.fq | awk '$awk2' | cut -d' ' -f2 | cut -c1-4 > $outDir/first4_{}.txt"

#reading every 4th line starting with line 2, get last 4 characters of sequence
< list_for_UMI.txt parallel -P4 "cat $inDir/NEXT_trim1.{}.fq | awk '$awk2' | sed 's/^.*\(.\{4\}\)/\1/' > $outDir/last4_{}.txt"

#pasting first UMI 4 nuc. with last UMI 4 nuc.
< list_for_UMI.txt parallel -P4 "paste -d'\0' $outDir/first4_{}.txt $outDir/last4_{}.txt > $outDir/UMI_{}.txt"

#quadruple UMIs
< list_for_UMI.txt parallel -P4 "awk '{for(i=0;i<4;i++)print}' $outDir/UMI_{}.txt >$outDir/quad_UMI_{}.txt"

# add an "_" to the front of every UMI line
awk3='$0="_"$0'
< list_for_UMI.txt parallel -P4 "awk '$awk3'  $outDir/quad_UMI_{}.txt > $outDir/final_UMI_{}.txt"

# add the UMI to the fastq file identifier line
awk4='{getline p<f} (NR%4==1){$1=$1" "$2;$2=p}1'
< list_for_UMI.txt parallel -P4 "awk '$awk4' OFS= f=$outDir/final_UMI_{}.txt $inDir/NEXT_trim1.{}.fq > $outDir/NEXT_{}_UMItools_R1.fq"

#remove reads from fastq with Ns in the UMI:
#< list_for_UMI.txt parallel -P4 "sed -e '/_N\|_.*N/,+3d' $outDir/NEXT_{}_UMItools_R1.fq > $outDir/NEXT_Ns_rem_{}_UMItools_R1.fq"

#remove random 4 base pair seqs that make up the UMI from the fastq read sequence line:
< list_for_UMI.txt parallel -P4 "/home/carrie/cutadapt -u 4 -o $outDir/trim2_{}_Ns_kept_forUMI_tools.fq $outDir/NEXT_{}_UMItools_R1.fq"

< list_for_UMI.txt parallel -P4 "/home/carrie/cutadapt -m 16 -u  -4 -o $outDir/trimmed_{}_Ns_kept_forUMI_tools.fq $outDir/trim2_{}_Ns_kept_forUMI_tools.fq"


#remove space form the identifier of the fastq
< list_for_UMI.txt parallel -P4 "sed 's/ /-/' $outDir/trimmed_{}_Ns_kept_forUMI_tools.fq > $outDir/nospace_trimmed_{}_Ns_kept_forUMI_tools.fq"

#bowtie alignment
< list_for_UMI.txt parallel -P3 "/usr/bin/bowtie /media/DATA/carrie/miRge/miRge-master/miRge.seqLibs/human/mirna --fullref  -S $outDir/nospace_trimmed_{}_Ns_kept_forUMI_tools.fq $outDir/NEXT_{}_Ns_kept_readyforUMItools.sam"

#convert to bams
< list_for_UMI.txt parallel -P3 "samtools view -bS -o $outDir/NEXT_{}_Ns_kept_readyforUMItools.bam $outDir/NEXT_{}_Ns_kept_readyforUMItools.sam"

#index and sort bams
< list_for_UMI.txt parallel -P3 "samtools sort $outDir/NEXT_{}_Ns_kept_readyforUMItools.bam $outDir/NEXT_{}_Ns_kept_readyforUMItools_sorted"
< list_for_UMI.txt parallel -P3 "samtools index $outDir/NEXT_{}_Ns_kept_readyforUMItools_sorted.bam"

#UMItools
< list_for_UMI.txt parallel -P3 "umi_tools dedup --method directional -I $outDir/NEXT_{}_Ns_kept_readyforUMItools_sorted.bam -S $outDir/directional_deduped_Ns_kept_{}_UMItools.bam"


#convert deduped bam files to fastq files
<list_for_UMI.txt parallel -P3 "bam2fastx -q -Q -A -o $outDir/directional_dedupped_Ns_kept_{}_TEST.fq $outDir/directional_deduped_Ns_kept_{}_UMItools.bam"
```


miRge command on SRV2
```{bash, eval = FALSE}
#located here: carrie@srv02:~/miRge/miRge-master/isomiR_study_2_20_18
<<<<<<< HEAD
perl miRge.pl --species human --diff-isomirs --phred64 --bowtie /usr/bin/bowtie --CPU 10 --SampleFiles Clontech_trimmed.1.fq,Clontech_trimmed.2.fq,Clontech_trimmed.3.fq,Clontech_trimmed.4.fq,Clontech_trimmed.5.fq,Clontech_trimmed.6.fq,Clontech_trimmed.7.fq,Clontech_trimmed.8.fq,Clontech_trimmed.9.fq,Clontech_trimmed.10.fq,Clontech_trimmed.11.fq,Clontech_trimmed.12.fq,Clontech_trimmed.13.fq,Clontech_trimmed.14.fq,Clontech_trimmed.15.fq,Clontech_trimmed.16.fq,Clontech_trimmed.17.fq,Clontech_trimmed.18.fq,Clontech_trimmed.1_acc.fq,Clontech_trimmed.2_acc.fq,Clontech_trimmed.3_acc.fq,Illumina_trimmed.1.fq,Illumina_trimmed.2.fq,Illumina_trimmed.3.fq,Illumina_trimmed.4.fq,Illumina_trimmed.5.fq,Illumina_trimmed.6.fq,Illumina_trimmed.7.fq,Illumina_trimmed.8.fq,Illumina_trimmed.9.fq,Illumina_trimmed.1_acc.fq,Illumina_trimmed.2_acc.fq,Illumina_trimmed.3_acc.fq,NEB_trimmed.1.fq,NEB_trimmed.2.fq,NEB_trimmed.3.fq,NEB_trimmed.4.fq,NEB_trimmed.5.fq,NEB_trimmed.6.fq,NEB_trimmed.7.fq,NEB_trimmed.8.fq,NEB_trimmed.9.fq,NEB_trimmed.10.fq,NEB_trimmed.11.fq,NEB_trimmed.12.fq,NEB_trimmed.1_acc.fq,NEB_trimmed.2_acc.fq,NEB_trimmed.3_acc.fq,NEXT_trimmed.1.fq,NEXT_trimmed.2.fq,NEXT_trimmed.3.fq,NEXT_trimmed.4.fq,NEXT_trimmed.5.fq,NEXT_trimmed.6.fq,NEXT_trimmed.7.fq,NEXT_trimmed.8.fq,NEXT_trimmed.9.fq,NEXT_trimmed.10.fq,NEXT_trimmed.11.fq,NEXT_trimmed.12.fq,NEXT_trimmed.13.fq,NEXT_trimmed.14.fq,NEXT_trimmed.15.fq,NEXT_trimmed.16.fq,NEXT_trimmed.17.fq,NEXT_trimmed.18.fq,NEXT_trimmed.1_acc.fq,NEXT_trimmed.2_acc.fq,NEXT_trimmed.3_acc.fq,directional_dedupped_Ns_kept_1_TEST.fq,directional_dedupped_Ns_kept_2_TEST.fq,directional_dedupped_Ns_kept_3_TEST.fq,directional_dedupped_Ns_kept_4_TEST.fq,directional_dedupped_Ns_kept_5_TEST.fq,directional_dedupped_Ns_kept_6_TEST.fq,directional_dedupped_Ns_kept_7_TEST.fq,directional_dedupped_Ns_kept_8_TEST.fq,directional_dedupped_Ns_kept_9_TEST.fq,directional_dedupped_Ns_kept_10_TEST.fq,directional_dedupped_Ns_kept_11_TEST.fq,directional_dedupped_Ns_kept_12_TEST.fq,directional_dedupped_Ns_kept_13_TEST.fq,directional_dedupped_Ns_kept_14_TEST.fq,directional_dedupped_Ns_kept_15_TEST.fq,directional_dedupped_Ns_kept_16_TEST.fq,directional_dedupped_Ns_kept_17_TEST.fq,directional_dedupped_Ns_kept_18_TEST.fq,directional_dedupped_Ns_kept_1_acc_TEST.fq,directional_dedupped_Ns_kept_2_acc_TEST.fq,directional_dedupped_Ns_kept_3_acc_TEST.fq


=======
perl miRge.pl --species human --diff-isomirs --phred64 --bowtie /usr/bin/bowtie --CPU 10 --SampleFiles Clontech_trimmed.1.fq,Clontech_trimmed.2.fq,Clontech_trimmed.3.fq,Clontech_trimmed.4.fq,Clontech_trimmed.5.fq,Clontech_trimmed.6.fq,Clontech_trimmed.7.fq,Clontech_trimmed.8.fq,Clontech_trimmed.9.fq,Clontech_trimmed.10.fq,Clontech_trimmed.11.fq,Clontech_trimmed.12.fq,Clontech_trimmed.13.fq,Clontech_trimmed.14.fq,Clontech_trimmed.15.fq,Clontech_trimmed.16.fq,Clontech_trimmed.17.fq,Clontech_trimmed.18.fq,Clontech_trimmed.1_acc.fq,Clontech_trimmed.2_acc.fq,Clontech_trimmed.3_acc.fq,Illumina_trimmed.1.fq,Illumina_trimmed.2.fq,Illumina_trimmed.3.fq,Illumina_trimmed.4.fq,Illumina_trimmed.5.fq,Illumina_trimmed.6.fq,Illumina_trimmed.7.fq,Illumina_trimmed.8.fq,Illumina_trimmed.9.fq,Illumina_trimmed.1_acc.fq,Illumina_trimmed.2_acc.fq,Illumina_trimmed.3_acc.fq,NEB_trimmed.1.fq,NEB_trimmed.2.fq,NEB_trimmed.3.fq,NEB_trimmed.4.fq,NEB_trimmed.5.fq,NEB_trimmed.6.fq,NEB_trimmed.7.fq,NEB_trimmed.8.fq,NEB_trimmed.9.fq,NEB_trimmed.10.fq,NEB_trimmed.11.fq,NEB_trimmed.12.fq,NEB_trimmed.1_acc.fq,NEB_trimmed.2_acc.fq,NEB_trimmed.3_acc.fq,NEXT_trimmed.1.fq,NEXT_trimmed.1.fq,NEXT_trimmed.2.fq,NEXT_trimmed.3.fq,NEXT_trimmed.4.fq,NEXT_trimmed.5.fq,NEXT_trimmed.6.fq,NEXT_trimmed.7.fq,NEXT_trimmed.8.fq,NEXT_trimmed.9.fq,NEXT_trimmed.10.fq,NEXT_trimmed.11.fq,NEXT_trimmed.12.fq,NEXT_trimmed.13.fq,NEXT_trimmed.14.fq,NEXT_trimmed.15.fq,NEXT_trimmed.16.fq,NEXT_trimmed.17.fq,NEXT_trimmed.18.fq,NEXT_trimmed.1_acc.fq,NEXT_trimmed.2_acc.fq,NEXT_trimmed.3_acc.fq,directional_dedupped_Ns_kept_1_TEST.fq,directional_dedupped_Ns_kept_1_TEST.fq,directional_dedupped_Ns_kept_1_TEST.fq,directional_dedupped_Ns_kept_1_TEST.fq,directional_dedupped_Ns_kept_1_TEST.fq,directional_dedupped_Ns_kept_1_TEST.fq,directional_dedupped_Ns_kept_1_TEST.fq,directional_dedupped_Ns_kept_1_TEST.fq,directional_dedupped_Ns_kept_1_TEST.fq,directional_dedupped_Ns_kept_2_TEST.fq,directional_dedupped_Ns_kept_3_TEST.fq,directional_dedupped_Ns_kept_4_TEST.fq,directional_dedupped_Ns_kept_5_TEST.fq,directional_dedupped_Ns_kept_6_TEST.fq,directional_dedupped_Ns_kept_7_TEST.fq,directional_dedupped_Ns_kept_8_TEST.fq,directional_dedupped_Ns_kept_9_TEST.fq,directional_dedupped_Ns_kept_10_TEST.fq,directional_dedupped_Ns_kept_11_TEST.fq,directional_dedupped_Ns_kept_12_TEST.fq,directional_dedupped_Ns_kept_13_TEST.fq,directional_dedupped_Ns_kept_14_TEST.fq,directional_dedupped_Ns_kept_15_TEST.fq,directional_dedupped_Ns_kept_16_TEST.fq,directional_dedupped_Ns_kept_17_TEST.fq,directional_dedupped_Ns_kept_18_TEST.fq,directional_dedupped_Ns_kept_1_acc_TEST.fq,directional_dedupped_Ns_kept_2_acc_TEST.fq,directional_dedupped_Ns_kept_3_acc_TEST.fq


#redoing
perl miRge.pl --species human --diff-isomirs --phred64 --bowtie /usr/bin/bowtie --CPU 10 --SampleFiles Clontech_trimmed.1.fq,Clontech_trimmed.2.fq,Clontech_trimmed.3.fq,Clontech_trimmed.4.fq,Clontech_trimmed.5.fq,Clontech_trimmed.6.fq,Clontech_trimmed.7.fq,Clontech_trimmed.8.fq,Clontech_trimmed.9.fq,Clontech_trimmed.10.fq,Clontech_trimmed.11.fq,Clontech_trimmed.12.fq,Clontech_trimmed.13.fq,Clontech_trimmed.14.fq,Clontech_trimmed.15.fq,Clontech_trimmed.16.fq,Clontech_trimmed.17.fq,Clontech_trimmed.18.fq,Clontech_trimmed.1_acc.fq,Clontech_trimmed.2_acc.fq,Clontech_trimmed.3_acc.fq,Illumina_trimmed.1.fq,Illumina_trimmed.2.fq,Illumina_trimmed.3.fq,Illumina_trimmed.4.fq,Illumina_trimmed.5.fq,Illumina_trimmed.6.fq,Illumina_trimmed.7.fq,Illumina_trimmed.8.fq,Illumina_trimmed.9.fq,Illumina_trimmed.1_acc.fq,Illumina_trimmed.2_acc.fq,Illumina_trimmed.3_acc.fq,NEB_trimmed.1.fq,NEB_trimmed.2.fq,NEB_trimmed.3.fq,NEB_trimmed.4.fq,NEB_trimmed.5.fq,NEB_trimmed.6.fq,NEB_trimmed.7.fq,NEB_trimmed.8.fq,NEB_trimmed.9.fq,NEB_trimmed.10.fq,NEB_trimmed.11.fq,NEB_trimmed.12.fq,NEB_trimmed.1_acc.fq,NEB_trimmed.2_acc.fq,NEB_trimmed.3_acc.fq,NEXT_trimmed.1.fq,NEXT_trimmed.2.fq,NEXT_trimmed.3.fq,NEXT_trimmed.4.fq,NEXT_trimmed.5.fq,NEXT_trimmed.6.fq,NEXT_trimmed.7.fq,NEXT_trimmed.8.fq,NEXT_trimmed.9.fq,NEXT_trimmed.10.fq,NEXT_trimmed.11.fq,NEXT_trimmed.12.fq,NEXT_trimmed.13.fq,NEXT_trimmed.14.fq,NEXT_trimmed.15.fq,NEXT_trimmed.16.fq,NEXT_trimmed.17.fq,NEXT_trimmed.18.fq,NEXT_trimmed.1_acc.fq,NEXT_trimmed.2_acc.fq,NEXT_trimmed.3_acc.fq,directional_dedupped_Ns_kept_1_TEST.fq,directional_dedupped_Ns_kept_2_TEST.fq,directional_dedupped_Ns_kept_3_TEST.fq,directional_dedupped_Ns_kept_4_TEST.fq,directional_dedupped_Ns_kept_5_TEST.fq,directional_dedupped_Ns_kept_6_TEST.fq,directional_dedupped_Ns_kept_7_TEST.fq,directional_dedupped_Ns_kept_8_TEST.fq,directional_dedupped_Ns_kept_9_TEST.fq,directional_dedupped_Ns_kept_10_TEST.fq,directional_dedupped_Ns_kept_11_TEST.fq,directional_dedupped_Ns_kept_12_TEST.fq,directional_dedupped_Ns_kept_13_TEST.fq,directional_dedupped_Ns_kept_14_TEST.fq,directional_dedupped_Ns_kept_15_TEST.fq,directional_dedupped_Ns_kept_16_TEST.fq,directional_dedupped_Ns_kept_17_TEST.fq,directional_dedupped_Ns_kept_18_TEST.fq,directional_dedupped_Ns_kept_1_acc_TEST.fq,directional_dedupped_Ns_kept_2_acc_TEST.fq,directional_dedupped_Ns_kept_3_acc_TEST.fq

#redoing again


carrie@srv02:~/miRge/miRge-master$ perl miRge.pl --species human --diff-isomirs --phred64 --bowtie /usr/bin/bowtie --CPU 10 --SampleFiles Clontech_trimmed.1_acc.fq,Clontech_trimmed.2_acc.fq,Clontech_trimmed.3_acc.fq,Illumina_trimmed.1_acc.fq,Illumina_trimmed.2_acc.fq,Illumina_trimmed.3_acc.fq,NEB_trimmed.1_acc.fq,NEB_trimmed.2_acc.fq,NEB_trimmed.3_acc.fq,NEXT_trimmed.1_acc.fq,NEXT_trimmed.2_acc.fq,NEXT_trimmed.3_acc.fq,directional_deduped_int_trim_Ns_rem_1_acc.fq,directional_deduped_int_trim_Ns_rem_2_acc.fq,directional_deduped_int_trim_Ns_rem_3_acc.fq,Clontech_trimmed.1.fq,Clontech_trimmed.2.fq,Clontech_trimmed.3.fq,Clontech_trimmed.4.fq,Clontech_trimmed.5.fq,Clontech_trimmed.6.fq,Clontech_trimmed.7.fq,Clontech_trimmed.8.fq,Clontech_trimmed.9.fq,Clontech_trimmed.10.fq,Clontech_trimmed.11.fq,Clontech_trimmed.12.fq,Clontech_trimmed.13.fq,Clontech_trimmed.14.fq,Clontech_trimmed.15.fq,Clontech_trimmed.16.fq,Clontech_trimmed.17.fq,Clontech_trimmed.18.fq,Illumina_trimmed.1.fq,Illumina_trimmed.2.fq,Illumina_trimmed.3.fq,Illumina_trimmed.4.fq,Illumina_trimmed.5.fq,Illumina_trimmed.6.fq,Illumina_trimmed.7.fq,Illumina_trimmed.8.fq,Illumina_trimmed.9.fq,NEB_trimmed.1.fq,NEB_trimmed.2.fq,NEB_trimmed.3.fq,NEB_trimmed.4.fq,NEB_trimmed.5.fq,NEB_trimmed.6.fq,NEB_trimmed.7.fq,NEB_trimmed.8.fq,NEB_trimmed.9.fq,NEB_trimmed.10.fq,NEB_trimmed.11.fq,NEB_trimmed.12.fq,NEXT_trimmed.1.fq,NEXT_trimmed.2.fq,NEXT_trimmed.3.fq,NEXT_trimmed.4.fq,NEXT_trimmed.5.fq,NEXT_trimmed.6.fq,NEXT_trimmed.7.fq,NEXT_trimmed.8.fq,NEXT_trimmed.9.fq,NEXT_trimmed.10.fq,NEXT_trimmed.11.fq,NEXT_trimmed.12.fq,NEXT_trimmed.13.fq,NEXT_trimmed.14.fq,NEXT_trimmed.15.fq,NEXT_trimmed.16.fq,NEXT_trimmed.17.fq,NEXT_trimmed.18.fq,directional_deduped_int_trim_Ns_rem_1.fq,directional_deduped_int_trim_Ns_rem_2.fq,directional_deduped_int_trim_Ns_rem_3.fq,directional_deduped_int_trim_Ns_rem_4.fq,directional_deduped_int_trim_Ns_rem_5.fq,directional_deduped_int_trim_Ns_rem_6.fq,directional_deduped_int_trim_Ns_rem_7.fq,directional_deduped_int_trim_Ns_rem_8.fq,directional_deduped_int_trim_Ns_rem_9.fq,directional_deduped_int_trim_Ns_rem_10.fq,directional_deduped_int_trim_Ns_rem_11.fq,directional_deduped_int_trim_Ns_rem_12.fq,directional_deduped_int_trim_Ns_rem_13.fq,directional_deduped_int_trim_Ns_rem_14.fq,directional_deduped_int_trim_Ns_rem_15.fq,directional_deduped_int_trim_Ns_rem_16.fq,directional_deduped_int_trim_Ns_rem_17.fq,directional_deduped_int_trim_Ns_rem_18.fq
```

#Generate count data
```{r}
library(here)

isomiR_Counts <-read.table(here("Complete_data/IsomiR_data/isomirs.csv"), header = TRUE, sep = ",", row.names = NULL)
colnames(isomiR_Counts)<-colnames(isomiR_Counts)[-(grep("row.names", colnames(isomiR_Counts)))]# shift everything to right
isomiR_Counts<-as.data.frame(isomiR_Counts)
# Entropy <- isomiR_Counts$Entropy
# 
Pheno<- read.table(here("Complete_data/Pheno.txt"), header = T)
Pheno <- Pheno[-2,]
Pheno$Kit <- gsub("Five_double","Fivepercent", Pheno$Kit)
Pheno$Kit <- gsub("NEXTflex_deduped","Deduped", Pheno$Kit)
Counts <-isomiR_Counts[3:(length(isomiR_Counts) -2)]
Counts <-Counts[,-2]
 #Counts <-Counts[6:length(Counts)]# to remove extra files.....
# 
 colnames(Counts)<-gsub("directional_dedupped|directional_deduped", "Deduped", colnames(Counts))
 colnames(Counts)<-gsub("NEXT_", "NEXTflex_", colnames(Counts))
 annotation <-isomiR_Counts[1:2]

save(Counts, file =here("Complete_data/IsomiR_data/Counts.rda"))
#save(Entropy, file = here("Complete_data/IsomiR_data/Entropy.rda"))
save(annotation, file = here("Complete_data/IsomiR_data/annotation.rda"))
#save(Pheno, file = here("IsomiR_data/Pheno.rda"))
```

Need to convert from RPM to raw counts

```{r}
library(here)
load(here("Complete_data/IsomiR_data/Counts.rda"))
iso_RPM <-Counts

library(XML)
report_url<-here("Complete_data/report.html")# from miRge
urltxt <- readLines(report_url)
report<-readHTMLTable(doc = report_url, header = TRUE) #need to read every third line
report <- report [-length(report)]
report <-as.data.frame(report)
report <-report[1:9]
report <-report[seq(from =1, to = nrow(report), by = 5),]# remove extra empty lines
report <-report[-2,]
#report <- report[6:length(report$NULL.File.name.s.),]#remove extra files
total_reads <-as.numeric(as.character(report$NULL.Total.Input.Reads))# all isomir and canoncial reads
total_miRNA<-vapply(strsplit(as.character(report$NULL.All.miRNA.Reads...Filtered.miRNA.Reads),"/"),`[`, 2, FUN.VALUE=character(1))#need to use the filtered number of miRNA reads
total_miRNA<-gsub("[[:blank:]]", "", total_miRNA)
total_miRNA<-as.numeric(as.character(total_miRNA))

rep.row<-function(x,n){
   matrix(rep(x,each=n),nrow=n)
}
dimensions<-dim(iso_RPM)
Totalmatrix<-rep.row((total_miRNA/1000000), dimensions[1])#width of isoRPM2

iso_Raw<- (iso_RPM)*(as.numeric(Totalmatrix))
iso_Raw <- round(iso_Raw,digits = 0)
save(iso_Raw, file = here("Complete_data/IsomiR_data/Iso_raw.rda"))
save(Pheno, file = here("Complete_data/IsomiR_data/Pheno.rda"))
save(total_miRNA, report, file = here("Complete_data/IsomiR_data/total_miRNA.rda"))
```

#load processed data
```{r,eval = TRUE}
library(here)
#load(here("IsomiR_data/Entropy.rda"))
load(here("Complete_data/IsomiR_data/Iso_raw.rda"))
load(here("Complete_data/IsomiR_data/annotation.rda"))
load(here("Complete_data/IsomiR_data/Pheno.rda"))
load(here("Complete_data/IsomiR_data/total_miRNA.rda"))
```

Normalization... I think I only need to do by kit...
###DESeq2
```{r, eval=FALSE, warning=FALSE, message=FALSE, echo =FALSE}
library(DESeq2)
library(reshape2)
library(ggplot2)
full_norm_miR <-list()
Pheno$Kit<- factor(Pheno$Kit)
dds<-DESeqDataSetFromMatrix(countData = iso_Raw, colData = Pheno, design = ~ Kit)
dds <- estimateSizeFactors(dds)
full_norm_miR<-data.frame(counts(dds, normalized = TRUE))
save(Pheno, full_norm_miR, file = here("Complete_data/IsomiR_data/fullnorm_miR.rda"))

Pheno<-Pheno[7:99,]
iso_Raw<-iso_Raw[,7:99]
one_batch_norm_miR <-list()
Pheno$Kit<- factor(Pheno$Kit)
dds<-DESeqDataSetFromMatrix(countData = iso_Raw, colData = Pheno, design = ~ Kit)
dds <- estimateSizeFactors(dds)
one_batch_norm_miR<-data.frame(counts(dds, normalized = TRUE))
save(Pheno, one_batch_norm_miR, file = here("Complete_data/IsomiR_data/one_batch_norm_miR.rda"))

```

Could do fancier normalization
```{r, eval = FALSE, echo = FALSE}
Pheno$startingAmt<-paste0("starting_amt_", Pheno$startingAmt)
###split the data by starting Amount
split_startingAmt <- list() 
for(i in Pheno$startingAmt) { 
  split_startingAmt[[i]] <- data.frame(iso_Raw[which(Pheno$startingAmt==i)])
}
###split the pheno by starting Amount
Pheno_Amt <- list() 
for(i in Pheno$startingAmt) { 
  Pheno_Amt[[i]] <- data.frame(Pheno[which(Pheno$startingAmt==i),])
}

# library(edgeR)
# norm_miR <-list()
# for(i in unique(Pheno$startingAmt)){
# d<-DGEList(counts = split_startingAmt[[i]], group = Pheno$Kit[which(Pheno$startingAmt==i)])
# miR_TMM_edgeR_factors <-calcNormFactors(d, method = "TMM")
# TMM <-estimateCommonDisp(miR_TMM_edgeR_factors)
# norm_miR[[i]] <-data.frame(TMM$pseudo.counts)
# }


```


#################################################################START HERE####################
#summarized data
```{r}
library(here)
library(ggplot2)
load(here("Complete_data/IsomiR_data/one_batch_norm_miR.rda"))
load(here("Complete_data/IsomiR_data/total_miRNA.rda"))
#load(here("Complete_data/IsomiR_data/Pheno.rda"))
norm_miRDF <-data.frame(one_batch_norm_miR)
total_isomiRs_above10 <- colSums(norm_miRDF>100)
total_isomiR_reads <- colSums(norm_miRDF)
total_isomiR_reads <-data.frame(total_isomiR_reads)
total_isomiRs_above10<-data.frame(total_isomiRs_above10)
total_isomiR<-cbind(total_isomiR_reads, total_isomiRs_above10)

isomiR_DATA <- data.frame(total_isomiRs = total_isomiRs_above10$total_isomiRs_above10, Kit = Pheno$Kit, StartingAmt =Pheno$startingAmt)
isomiR_DATA$Kit <- factor(isomiR_DATA$Kit,levels = c("Clontech", "Illumina", "NEB", "NEXTflex", "Deduped", "Fivepercent"), ordered = TRUE)

#ggplot(data =isomiR_DATA, aes(x = Kit, y = total_isomiRs, fill = Kit)) +geom_boxplot()+facet_grid(.~StartingAmt)
#ggplot(data =isomiR_DATA, aes(x = Kit, y = total_isomiRs, fill = Kit)) +geom_boxplot()+facet_grid(StartingAmt~.) + geom_jitter(aes(color = Kit))
#ggplot(data =isomiR_DATA, aes(x = StartingAmt, y = total_isomiRs, fill = Kit)) +geom_point(aes(x = StartingAmt, y = total_isomiRs))+facet_grid(.~Kit) + geom_jitter(aes(color = Kit))

ggplot(data = isomiR_DATA, aes(x = StartingAmt, y = total_isomiRs, group = StartingAmt)) + geom_jitter(aes(color = Kit))+ geom_boxplot(aes(fill = Kit)) + facet_grid(.~Kit) + scale_x_continuous(breaks=unique(isomiR_DATA$StartingAmt)) + theme(legend.position = "none", axis.text.x = element_text(size =14, angle = 60, hjust = 1), axis.text.y = element_text(size =14, hjust = 1), axis.title=element_text(size = 20), plot.title = element_text(size = 20)) + labs(y = " Number of Uniquely Detected miRNA Sequences", title = "isomiRNA Detection across kits") +geom_smooth(method = "loess", se=TRUE, color="black", aes(group=1))  


ggplot(data = isomiR_DATA, aes(x = StartingAmt, y = total_isomiRs, group = StartingAmt)) + geom_jitter(aes(color = Kit))+ geom_boxplot(outlier.shape = NA, aes(fill = Kit)) + facet_grid(.~Kit) + scale_x_continuous(breaks=unique(isomiR_DATA$StartingAmt)) + theme(legend.position = "none", axis.text.x = element_text(size =10, angle = 60, hjust = 1,face = "bold"), axis.text.y = element_text(size =20, hjust = 1), axis.title=element_text(size = 20), plot.title = element_text(size = 20), strip.text.x = element_text(size = 20), axis.title.x = element_text(size = 0), axis.title.y= element_text(size = 17)) + labs(y = " Uniquely Detected isomiRs", title = "isomiRNA Detection Across Kits") +geom_smooth(method = "loess", se=TRUE, color="black", aes(group=1, fill = Kit))


#total_reads <-as.numeric(as.character(report$NULL.Total.Input.Reads))


#summarized_Data <- data.frame(total_miRNA=(as.data.frame(total_miRNA)), totalreads =report$NULL.Total.Input.Reads)
#summarized_Data$percentmiRNA <- (as.numeric(summarized_Data$total_miRNA)/as.numeric(as.character(summarized_Data$totalreads)))*100
#summarized_Data$Kit <- Pheno$Kit



```
#stats
Is there a relationship between starting amount and the number detected
```{r}
library(broom)
det_mod <-lm(isomiR_DATA$total_isomiRs ~ isomiR_DATA$StartingAmt)
summary(det_mod)
det_mod <-lm(isomiR_DATA$total_isomiRs ~isomiR_DATA$Kit)
summary(det_mod)

split_kit <-list()
for(i in isomiR_DATA$Kit) { 
  split_kit[[i]] <- data.frame(isomiR_DATA[which(isomiR_DATA$Kit==i),])
} 
#Det_data$Starting_Amount<-factor(Det_data$Starting_Amount)
 run_model <-function(x){(lm(x[["total_isomiRs"]]~x[["StartingAmt"]]))}
model_stats<-lapply(split_kit,run_model)
model_summary<-lapply(model_stats, summary)
lapply(model_summary, glance)# just last 3

model_summary$Deduped
split_amt <-list()
for(i in unique(as.character(isomiR_DATA$StartingAmt))) { 
  split_amt[[i]] <- data.frame(isomiR_DATA[which(isomiR_DATA$StartingAmt==i),])
} 
 run_model <-function(x){(lm(x[["total_isomiRs"]]~x[["Kit"]]))}
model_stats<-lapply(split_amt,run_model)
model_summary<-lapply(model_stats, summary)
lapply(model_summary, glance)# all significant


  t.test(split_kit$Clontech$total_isomiRs, split_kit$NEXTflex$total_isomiRs)

t.test(split_amt$`100`$total_isomiRs[grep("Clontech",split_amt$`100`$Kit)], split_amt$`100`$total_isomiRs[grep("NEB", split_amt$`100`$Kit)])

#Det <-t(detected)
#colnames(Det)<- Pheno$Kit
#split_amt <-list()
#for(i in unique(Pheno$startingAmt)) { 
#    split_amt[[i]] <- data.frame(Det[,which(Pheno$startingAmt==i), drop = FALSE])
#    colnames(split_amt[[i]]) <- Pheno$Kit[which(Pheno$startingAmt==i)]}


```


```{r, echo = TRUE, eval=TRUE}
library(dplyr)
get_test_names <- function(data){
  test_names <<- data.frame(combn(unique(names(data)), m= 2))
}

get_test_results<- function(data,test_names) {
  tresults<<-list()
  tested_names1<<-list()
  tested_names2<<-list()
  for(i in names(test_names)){
    #tested_names[[i]]<<-(test_names[i][,1])
    Kit1<-data[grep(test_names[i][1,], names(data))]
    Kit2<-data[grep(test_names[i][2,], names(data))]
    #Kit1<-data.frame(select(data, names(data)[names(data) %in% test_names[i][1,]]))
    #Kit2<-data.frame(select(data, names(data)[names(data) %in% test_names[i][2,]]))
    tested_names1[[i]]<<-names(Kit1)
    tested_names2[[i]]<<-names(Kit2)
    # colnames(Kit1)<-c("error")
    # colnames(Kit2)<-c("error")
    tresults[[i]]<<-t.test(x=Kit1[[1]][4], y=Kit2[[1]][4], paired = FALSE) ### may have messed things up adding paired = TRUE previously had more ))
    tested_kits <<-paste0(tested_names1, "&", tested_names2)
  }
}

get_ttestStats<- function(x) {
  #print(length(test_names))
  c(t =format(x$statistic, digits = 2),
    df = format(x$parameter, digits = 0),
    p.value = format(x$p.value, scientific = TRUE, digits = 2),
    bonferroni_thresh = format(.05/length(test_names), digits = 2),
    sig = ifelse(x$p.value<(.05/length(test_names)), "yes", "no"))
}

#get_lmStats <-function(x) {
#  c(p=x$coefficients[2,4], scientific = TRUE, digits =2)
#}
```

```{r}
get_test_names(split_kit)
get_test_results(data = split_kit, test_names = test_names)
ttestStats_across<-data.frame(lapply(tresults, get_ttestStats))
colnames(ttestStats_across)<-tested_kits
ttestStats_across
```


#dont run too slow
Threshold across triplicates
```{r, eval = FALSE}
library(genefilter)
library(reshape2)
norm_miR <- one_batch_norm_miR
isomiR_DATA <- data.frame(total_isomiRs = total_isomiRs_above10$total_isomiRs_above10, Kit = Pheno$Kit, StartingAmt =Pheno$startingAmt)
isomiR_DATA$Kit <- factor(isomiR_DATA$Kit,levels = c("Clontech", "Illumina", "NEB", "NEXTflex", "Deduped", "Fivepercent"), ordered = TRUE)

isomiR_DATA$StartingAmt<-paste0("starting_amt_", isomiR_DATA$StartingAmt)


Pheno$startingAmt <-factor(Pheno$startingAmt)
split_kit_isoData <- list()
for(i in unique(Pheno$startingAmt)) {
  for(kit in unique(Pheno$Kit)){
  split_kit_isoData[[i]][[kit]] <- data.frame(norm_miR[which(Pheno$startingAmt == as.character(i) & Pheno$Kit == as.character(kit))])}
}

poverafun <- genefilter::pOverA(p = 1, A = 100)#at least 100 normalized reads in all samples of the set... 
ffun <- filterfun(poverafun)
genefilt_fun<- function(x){genefilter(x, ffun)}

thresh <-list()
for(amt in names(split_kit_isoData)){
thresh[[amt]]<-lapply(split_kit_isoData[[as.character(amt)]], genefilt_fun)}

test <-split_kit_isoData$`100`$Clontech[thresh$`100`$Clontech,]

split_amt_thresh <-list()
for(amt in names(split_kit_isoData)){
for(kit in names(split_kit_isoData[[amt]])){
 split_amt_thresh[[amt]][[kit]]<- split_kit_isoData[[amt]][[kit]][thresh[[amt]][[kit]],]}
}

thresh_number <- list()
for(amt in names(split_kit_isoData)){
for(kit in names(split_kit_isoData[[amt]])){
thresh_number[[amt]][[kit]]<- dim(split_kit_isoData[[amt]][[kit]][thresh[[amt]][[kit]],])[1]}
}

thresh_number <-data.frame(thresh_number)
colnames(thresh_number) <-c("100", "250", "500", "1000", "1500", "2000")
thresh_number$kit <- rownames(thresh_number)
thresh_number <-melt(thresh_number)
thresh_number$variable <-as.numeric(as.character(thresh_number$variable))
thresh_number<-thresh_number[-which(thresh_number$value =="0"),]
thresh_number$kit <- factor(thresh_number$kit,levels = c("Clontech", "Illumina", "NEB", "NEXTflex", "Deduped", "Fivepercent"))

save(thresh, thresh_number, file = here("Complete_data/IsomiR_data/thresh_number.rda") )
```

plot of threshold across Triplicates
```{r}
load(here("Complete_data/IsomiR_data/thresh_number.rda"))
ggplot(data = thresh_number, aes(x = variable, y = value, group = variable)) + geom_jitter(aes(col = kit))+ facet_grid(.~kit) + scale_x_continuous(breaks=unique(thresh_number$variable)) + theme(legend.position = "none", axis.text.x = element_text(angle = 45, hjust = 1)) + labs(y = " Number of Uniquely Detected miRNA Sequences", title = "isomiRNA Detection across kits > 10 reads in all triplicates") +geom_smooth(method = "lm", se=TRUE, color="black", aes(group=1))

```


How consistent are the results...
```{r}

library(genefilter)
library(VennDiagram)
library(reshape2)
library(ggplot2)
library(tidyr)

##filter each sample individually
total_isomiRs_above10
det_Data <- cbind(total_isomiRs_above10, Pheno$startingAmt, Pheno$Kit) # its really a hundred... not ten
colnames(det_Data)<- c("det_indv_thresh", "startingAmt", "kit")

#filter across triplicates
to_repeat <-function(x) { rep(x,3)}
thresh_kits <-data.frame(thresh_number)
thresh_kits <-spread(thresh_kits, kit, value)
Clontech <-data.frame(t=unlist(lapply(thresh_kits$Clontech[1:6], to_repeat)))
Illumina<-data.frame(t=unlist(lapply(thresh_kits$Illumina[4:6], to_repeat)))
NEB<-data.frame(t=unlist(lapply(thresh_kits$NEB[1:4], to_repeat)))
NEXTflex<-data.frame(t=unlist(lapply(thresh_kits$NEXTflex[1:6], to_repeat)))
Deduped<-data.frame(t=unlist(lapply(thresh_kits$Deduped[1:6], to_repeat)))
Fivepercent<- data.frame(t=unlist(lapply(thresh_kits$Fivepercent[1:6], to_repeat)))

thresh_across_amts<-rbind(Clontech, Illumina, NEB, NEXTflex, Deduped, Fivepercent)

load(here("Complete_data/IsomiR_data/annotation.rda"))
Clontech1000_anno <-annotation[thresh$`1000`$Clontech,]
Illumina1000_anno <-annotation[thresh$`1000`$Illumina,]
NEB1000_anno <-annotation[thresh$`1000`$NEB,]
NEXTflex1000_anno <-annotation[thresh$`1000`$NEXTflex,]
Deduped1000_anno <-annotation[thresh$`1000`$Deduped,]
Fivepercent1000_anno <-annotation[thresh$`1000`$Fivepercent,]

load(here("hsa_miRNA_info.rda"))
miRNA_hsa_sequences <-seqs_human$cDNA

canonicalseqs <-paste(miRNA_hsa_sequences,collapse="|")
canonicalseqs <-paste0(miRNA_hsa_sequences,collapse="|")
# grep(paste0(miRNA_hsa_sequences[1:1000],collapse="|"), test_isomirs)
# grep(paste0(miRNA_hsa_sequences[1:10000],collapse="|"), test_isomirs)# there is some other expression somewhere
# 
# grep(paste0(miRNA_hsa_sequences[1:2500],collapse="|"), test_isomirs) # no error
# grep(paste0(miRNA_hsa_sequences[1:2600],collapse="|"), test_isomirs) # gives an error
# grep(paste0(miRNA_hsa_sequences[2500:2600],collapse="|"), test_isomirs) # gives no error... maybe there is a grep limit? looks like 2538 yup!
# grep(("TTCAAG|TTC"), test_isomirs)
# grep(("TTCAAG"), test_isomirs)
# grep(("TTC"), test_isomirs)# should be only one canonical sequence per isomiR - so if a full length with canonical sequence exists within an isomiR with additonal nucleotides, it should be counted

write.csv(miRNA_hsa_sequences, file = here("miRNA_hsa_sequences.csv"))

Clontech_1000_isomirs <-Clontech1000_anno$sequence
Illumina_1000_isomirs <- Illumina1000_anno$sequence
NEB_1000_isomirs <- NEB1000_anno$sequence
NEXTflex_1000_isomirs <- NEXTflex1000_anno$sequence
Deduped_1000_isomirs <- Deduped1000_anno$sequence
Fivepercent_1000_isomirs <- Fivepercent1000_anno$sequence

write.table(Clontech_1000_isomirs, file = here("Clontech_1000_isomirsfull.csv"), sep="\t")
write.csv(Illumina_1000_isomirs, file = here("Illumina_1000_isomirsfull.csv"))
write.csv(NEB_1000_isomirs, file = here("NEB_1000_isomirsfull.csv"))
write.csv(NEXTflex_1000_isomirs, file = here("NEXTflex_1000_isomirsfull.csv"))
write.csv(Deduped_1000_isomirs, file = here("Deduped_1000_isomirsfull.csv"))
write.csv(Fivepercent_1000_isomirs, file = here("Fivepercent_1000_isomirsfull.csv"))

det_Data$det_across_thresh<-thresh_across_amts$t
det_Data$not_consistent <- ((det_Data$det_indv_thresh - as.numeric(as.character(det_Data$det_across_thresh)))/det_Data$det_indv_thresh)*100
  det_Data$not_consistent <- (abs(as.numeric(as.character(det_Data$det_indv_thresh)) -det_Data$det_across_thresh)/ det_Data$det_indv_thresh)*100
detected <-data.frame(det_Data$kit, det_Data$startingAmt, det_Data$not_consistent)

detected$det_Data.kit<-factor(detected$det_Data.kit, levels = c("Clontech", "Illumina", "NEB", "NEXTflex", "Deduped","Fivepercent"))
detected$det_Data.startingAmt <-gsub("starting_amt_", "",detected$det_Data.startingAmt)
detected$det_Data.startingAmt<-factor(detected$det_Data.startingAmt, levels = c("100", "250", "500", "1000", "1500","2000"))








ggplot(detected, aes(x =det_Data.kit, y=det_Data.not_consistent, fill = det_Data.kit)) + geom_boxplot()+ facet_grid(.~det_Data.startingAmt)

pdf(file =here("Figures/Raw_plots/isomiR_inconsistency.pdf"),width=10,height=6, onefile=FALSE)
ggplot(detected, aes(x =det_Data.startingAmt, y=det_Data.not_consistent, fill = det_Data.kit)) + geom_boxplot()+ facet_grid(.~det_Data.kit) + theme(legend.position = "none", axis.text.x = element_text(size =17, angle = 60, hjust = 1), axis.text.y = element_text(size =15, hjust = 1), axis.title=element_text(size = 20), plot.title = element_text(size = 30), strip.text.x = element_text(size = 20)) + labs( x= "Starting Amount", y = " Percentage of Inconsistently \n Detected isomiR Sequences", title = "Inconsistentcy of isomiR Detection Across Kits") +geom_smooth(method = "loess", se=TRUE, color="black", aes(group=1))+ylim(c(0,30))
dev.off()

ggplot(detected, aes(x =det_Data.kit, y=det_Data.not_consistent, fill = det_Data.kit)) + geom_boxplot()


#miRNA_det<-list("Clontech" = Clontech, "Illumina" = Illumina, "NEB" = NEB, "NextFlex" =NEXTflex)

miRNA_det<-list("Clontech\n(N=427)" = Clontech, "Illumina\n(N=443)" = Illumina, "NEB\n(N=450)" = NEB, "NextFlex\n(N=380)" =NEXTflex, "Deduped\n(N=427)" = Deduped)

library(sjstats)
summary(lm(det_Data$not_consistent~ det_Data$kit)) #sig difference in det inconsisentency across methods
anova_stats(anova(lm(det_Data$not_consistent~ det_Data$kit)))
#vp_alpha <- venn.diagram(miRNA_det, fill = c("red", "white", "blue", "green"), alpha = 0.5, filename = NULL)

det_Data$startingAmt <-as.numeric(as.character(det_Data$startingAmt))
summary(lm(det_Data$not_consistent~ det_Data$startingAmt)) #sig difference in det inconsisentency across methods
cor(det_Data$not_consistent, det_Data$startingAmt)
Clontech <- det_Data[which(det_Data$kit == "Clontech"),]
summary(lm(Clontech$not_consistent~Clontech$startingAmt))#F-statistic: 4.128 on 1 and 16 DF,  p-value: 0.05913
cor(Clontech$not_consistent,Clontech$startingAmt)
NEB<- det_Data[which(det_Data$kit == "NEB"),]
cor(NEB$not_consistent,NEB$startingAmt)

summary(lm(NEB$not_consistent~NEB$startingAmt))
NEXTflex<- det_Data[which(det_Data$kit == "NEXTflex"),]
summary(lm(NEXTflex$not_consistent~NEXTflex$startingAmt))
Deduped<- det_Data[which(det_Data$kit == "Deduped"),]
summary(lm(Deduped$not_consistent~Deduped$startingAmt))#F-statistic: 32.44 on 1 and 16 DF,  p-value: 3.313e-05
Fivepercent<- det_Data[which(det_Data$kit == "Fivepercent"),]
cor(Fivepercent$not_consistent, Fivepercent$startingAmt)
summary(lm(Fivepercent$not_consistent~Fivepercent$startingAmt))#F-statistic: 11.86 on 1 and 16 DF,  p-value: 0.003334
Illumina<- det_Data[which(det_Data$kit == "Illumina"),]
summary(lm(Illumina$not_consistent~Illumina$startingAmt))

inconsistency <-list(Clontech$not_consistent, Illumina$not_consistent, NEB$not_consistent, NEXTflex$not_consistent, Deduped$not_consistent, Fivepercent$not_consistent)
inconsistency<-lapply(inconsistency, data.frame)
names(inconsistency)<-c("Clontech", "Illumina", "NEB", "NEXTflex", "Deduped", "Fivepercent")
get_test_names(inconsistency)

get_test_results<- function(data,test_names) {
  tresults<<-list()
  tested_names1<<-list()
  tested_names2<<-list()
  for(i in names(test_names)){
    #tested_names[[i]]<<-(test_names[i][,1])
    Kit1<-data[grep(test_names[i][1,], names(data))]
    Kit2<-data[grep(test_names[i][2,], names(data))]
    #Kit1<-data.frame(select(data, names(data)[names(data) %in% test_names[i][1,]]))
    #Kit2<-data.frame(select(data, names(data)[names(data) %in% test_names[i][2,]]))
    tested_names1[[i]]<<-names(Kit1)
    tested_names2[[i]]<<-names(Kit2)
    # colnames(Kit1)<-c("error")
    # colnames(Kit2)<-c("error")
    tresults[[i]]<<-t.test(x=Kit1[[1]][1], y=Kit2[[1]][1], paired = FALSE) ### may have messed things up adding paired = TRUE previously had more ))
    tested_kits <<-paste0(tested_names1, "&", tested_names2)
  }
}

get_test_results(data = inconsistency, test_names = test_names)
ttestStats_across<-data.frame(lapply(tresults, get_ttestStats))
colnames(ttestStats_across)<-tested_kits
ttestStats_across

#grid.draw(vp_alpha);
#venn.plot <- venn.diagram(
# x = miRNA_det,
#  filename = NULL
#)
#grid.draw(venn.plot)
```

```{r}
head(det_Data)

across <- data.frame(det_Data$kit, det_Data$startingAmt, det_Data$det_across_thresh)
raw_det<- data.frame(det_Data$kit, det_Data$startingAmt, det_Data$det_indv_thresh)
#across<-across[seq(from =1, t = length(det_Data$det_indv_thresh) , by = 3),]
across$det_Data.det_across_thresh<-as.numeric(as.character(across$det_Data.det_across_thresh))

across$det_Data.kit<-factor(detected$det_Data.kit, levels = c("Clontech", "Illumina", "NEB", "NEXTflex", "Deduped","Fivepercent"))
across$det_Data.startingAmt<-factor(detected$det_Data.startingAmt, levels = c("100", "250", "500", "1000", "1500","2000"))

raw_det$det_Data.kit<-factor(detected$det_Data.kit, levels = c("Clontech", "Illumina", "NEB", "NEXTflex", "Deduped","Fivepercent"))
raw_det$det_Data.startingAmt<-factor(detected$det_Data.startingAmt, levels = c("100", "250", "500", "1000", "1500","2000"))

ggplot(raw_det, aes(x =det_Data.startingAmt, y=det_Data.det_indv_thresh, fill = det_Data.kit)) + geom_boxplot() + geom_jitter(aes(color = det_Data.kit))+ facet_grid(.~det_Data.kit, scales="free") + theme(legend.position = "none", axis.text.x = element_text(size =17, angle = 60, hjust = 1), axis.text.y = element_text(size =15, hjust = 1), axis.title=element_text(size = 20), plot.title = element_text(size = 30), strip.text.x = element_text(size = 20)) + labs( x= "Starting Amount", y = " Detected miRNA Sequences", title = " miRNA Detection Across Kits") +geom_smooth(method = "loess", se=TRUE, color="black", aes(group=1))+ geom_line(data = across, linetype =2, size =1.0001, aes(x=det_Data.startingAmt, y=det_Data.det_across_thresh, group=det_Data.kit, colour=det_Data.kit)) + geom_point(data = across, aes(x=det_Data.startingAmt, y=det_Data.det_across_thresh, group=det_Data.kit, color = det_Data.kit), shape=24)

ggplot(raw_det, aes(x =det_Data.startingAmt, y=det_Data.det_indv_thresh, fill = det_Data.kit)) + geom_boxplot() + facet_grid(.~det_Data.kit) + theme(legend.position = "none", axis.text.x = element_text(size =17, angle = 60, hjust = 1), axis.text.y = element_text(size =10, hjust = 1), axis.title=element_text(size = 20), plot.title = element_text(size = 30), strip.text.x = element_text(size = 20)) + labs( x= "Starting Amount", y = " Detected isomiRNA Sequences", title = " isomiRNA Detection Across Kits") +geom_smooth(method = "loess", se=TRUE, color="black", aes(group=1))+ geom_line(data = across, linetype =2, size =1, aes(x=det_Data.startingAmt, y=det_Data.det_across_thresh, group=det_Data.kit, colour=det_Data.kit)) + geom_point(data = across, aes(x=det_Data.startingAmt, y=det_Data.det_across_thresh, group=det_Data.kit, color = det_Data.kit), shape=24)

#was 10 by 4

pdf(file =here("Figures/Raw_plots/isomiR_Det.pdf"),width=10,height=6, onefile=FALSE)
ggplot(raw_det, aes(x =det_Data.startingAmt, y=det_Data.det_indv_thresh, fill = det_Data.kit)) + geom_boxplot() + facet_grid(.~det_Data.kit) + theme(legend.position = "none", axis.text.x = element_text(size =17, angle = 60, hjust = 1), axis.text.y = element_text(size =15, hjust = 1), axis.title=element_text(size = 20), plot.title = element_text(size = 30), strip.text.x = element_text(size = 20)) + labs( x= "Starting Amount", y = " Detected isomiRNA Sequences", title = " isomiRNA Detection Across Kits") +geom_smooth(method = "loess", se=TRUE, color="black", aes(group=1))+ geom_line(data = across, linetype =2, size =1, aes(x=det_Data.startingAmt, y=det_Data.det_across_thresh, group=det_Data.kit, colour=det_Data.kit)) + geom_point(data = across, aes(x=det_Data.startingAmt, y=det_Data.det_across_thresh, group=det_Data.kit, color = det_Data.kit), shape=24)+ylim(c(150,1000))
dev.off()


#Just 1000ng

raw_det_1000 <- raw_det[which(raw_det$det_Data.startingAmt == "1000"),]
across_det_1000 <- across[which(across$det_Data.startingAmt == "1000"),]
across_1000<-aggregate(across_det_1000, by = list(across_det_1000$det_Data.kit), FUN = mean)
across_1000<-data.frame(Kit =across_1000$Group.1, Detection =across_1000$det_Data.det_across_thresh)


ggplot(raw_det_1000, aes(x =det_Data.kit, y=det_Data.det_indv_thresh, fill = det_Data.kit)) + geom_boxplot() + geom_jitter()  + theme(legend.position = "none", axis.text.x = element_text(size =17, angle = 60, hjust = 1), axis.text.y = element_text(size =15, hjust = 1), axis.title=element_text(size = 20), plot.title = element_text(size = 30), strip.text.x = element_text(size = 20)) + labs( x= "Starting Amount", y = " Detected miRNA Sequences", title = " miRNA Detection Across Kits")  + geom_boxplot(data = across, aes(x=det_Data.kit, y=det_Data.det_across_thresh, group=det_Data.kit, alpha = 0.7), color = "black") + geom_point(data = across, aes(x=det_Data.kit, y=det_Data.det_across_thresh, group=det_Data.kit), color = "black", shape=24)

pdf(file =here("Figures/Raw_plots/isomiR_1000ng_Det.pdf"),width=4,height=6, onefile=FALSE)
ggplot(across_1000, aes(x =Kit, y=Detection, fill = Kit)) + geom_bar(stat = "identity", aes(y =Detection, fill = Kit)) + theme(legend.position = "none", axis.text.x = element_text(size =17, angle = 60, hjust = 1, color = "black"), axis.text.y = element_text(size =18, hjust = 1, color = "black"), axis.title.y=element_text(size = 20)) + labs(y = " Detected Unique isomiRNA Sequences") +coord_cartesian(ylim=c(200,720))+ geom_text(aes(label = (Detection), size = 6, hjust = 0.5, vjust = 1.5) )
dev.off()

det_Data_1000 <- detected[which(detected$det_Data.startingAmt == "1000"),]

pdf(file =here("Figures/Raw_plots/isomiR_1000ng_inconsistency.pdf"),width=4,height=6, onefile=FALSE)
ggplot(det_Data_1000, aes(x =det_Data.kit, y=det_Data.not_consistent, fill = det_Data.kit))  + geom_boxplot() + geom_jitter(width = 0.3)+ theme(legend.position = "none", axis.text.x = element_text(size =17, angle = 60, hjust = 1), axis.text.y = element_text(size =15, hjust = 1), axis.title=element_text(size = 20), plot.title = element_text(size = 30), strip.text.x = element_text(size = 20)) + labs( x= "Starting Amount", y = " Percentage of Inconsistently \n Detected isomiRNA Sequences", title = "Inconsistentcy of isomiRNA Detection Across Kits")+coord_cartesian(ylim=c(0,30))
dev.off()

summary(lm(det_Data_1000$det_Data.not_consistent~ det_Data_1000$det_Data.kit)) #sig difference in det inconsisentency across methods
#main effect of NEB??? lower than the rest
library(tidyr)
det_Data_1000$sample <- rep(c(1,2,3),6)
#det_Data_1000$sample<-paste0(det_Data_1000$det_Data.kit, det_Data_1000$sample)
# det_Data <-spread(det_Data_1000, sample, det_Data.not_consistent)
# det_Data <-data.frame(t(det_Data))
# det_Data<-det_Data[-1,]
# det_Data<-det_Data[-1,]
# colnames(det_Data)<-c("Clontech", "Illumina", "NEB", "NEXTflex", "Deduped", "Fivepercent")
# get_test_names(det_Data)
# det_Data <-as.numeric(as.character)
# get_test_results(data = det_Data, test_names = test_names)
# ttestStats_across<-data.frame(lapply(tresults, get_ttestStats)) # no sig between any pairs...
# colnames(ttestStats_across)<-tested_kits
# ttestStats_across

```


X1) number of identified isomirs - can see on first plot
2) identity of identified isomirs - need to use annotation this could be useful - like venn diagrams ...but could just determine percentage instead?
3) expression of identified isomirs within a kit across triplicates - this is more in depth... so maybe good just to go ahead to this??/
4) expression of identified isomirs across kits or identity of identified isomirs

```{r}

lapply(split_amt_thresh[[as.character(amt)]], var)

```
#####start here for faster analysis

```{r}
load(here("isomiR_data_extended/iso_Raw.rda"))
load(here("isomiR_data_extended/iso_anno.rda"))
Pheno<- read.table(here("IsomiR_data/IsoPheno.txt"), header = T)
identical(colnames(iso_Raw), as.character(Pheno$File))
miR_counts <- read.table(here("isomiR_data_extended/miR.Counts.csv"),header = T, sep = ",")
miR_counts <-miR_counts[-grep("fq.", colnames(miR_counts))]# to remove extra files.....
miR_counts <-miR_counts[-grep("acc", colnames(miR_counts))]# to remove second batch of 1000ng files.....
Total_counts <-miR_counts[1,]
miR_counts <-miR_counts[-1,]
miR_counts <-miR_counts[-1]
#remove second batch of 1000ng starting input
iso_Raw <- iso_Raw[-grep("acc", colnames(iso_Raw))]
Pheno <- Pheno [-grep("acc", Pheno$File),]
```


### comparison of error for each kit for given starting amount
##Split the data
```{r}

Pheno$startingAmt<-paste0("starting_amt_", Pheno$startingAmt)
###split the data by starting Amount
split_startingAmt <- list() 
for(i in Pheno$startingAmt) { 
  split_startingAmt[[i]] <- data.frame(iso_Raw[which(Pheno$startingAmt==i)])
}
###split the pheno by starting Amount
Pheno_Amt <- list() 
for(i in Pheno$startingAmt) { 
  Pheno_Amt[[i]] <- data.frame(Pheno[which(Pheno$startingAmt==i),])
}

Can_split_startingAmt <- list() 
for(i in Pheno$startingAmt) { 
  Can_split_startingAmt[[i]] <- data.frame(miR_counts[which(Pheno$startingAmt==i)])
}
```
###TMM Normalization

Normalization by kit for each starting amount - to allow tests to compare kits at a given starting amt

Later will do normalization by starting amount for each kit  individually to compare how consistent the data is between starting amounts for each kit
```{r, eval= TRUE, echo =FALSE}
#library(tweeDEseq)
#miR_1000_TMM<-data.frame(normalizeCounts(miR_1000_raw)
#dim(norm_miR_1000)
#or
library(edgeR)

norm_miR <-list()
for(i in unique(Pheno$startingAmt)){
d<-DGEList(counts = split_startingAmt[[i]], group = Pheno$Kit[which(Pheno$startingAmt==i)])
miR_TMM_edgeR_factors <-calcNormFactors(d, method = "TMM")
TMM <-estimateCommonDisp(miR_TMM_edgeR_factors)
norm_miR[[i]] <-data.frame(TMM$pseudo.counts)
}

#str(norm_miR)

Can_norm_miR <-list()
for(i in unique(Pheno$startingAmt)){
d<-DGEList(counts =Can_split_startingAmt[[i]], group = Pheno$Kit[which(Pheno$startingAmt==i)])
miR_TMM_edgeR_factors <-calcNormFactors(d, method = "TMM")
TMM <-estimateCommonDisp(miR_TMM_edgeR_factors)
Can_norm_miR[[i]] <-data.frame(TMM$pseudo.counts)
}

```

Now split normalized data by kit for each amount
```{r}

split_norm_Amt <- list() 
for(i in names(norm_miR)) {
  for(kit in unique(Pheno_Amt[[i]][3]$Kit))# take the third list from each respective amount selected from norm_miR names - the third is the kit - so for each kit in the list of kits for a given amount...
  split_norm_Amt[[i]][[kit]] <-data.frame(norm_miR[[i]][which(Pheno_Amt[[i]][3] == kit)]) # take only the values that correspond to that kit for that amount
}

Can_split_norm_Amt <- list() 
for(i in names(Can_norm_miR)) {
  for(kit in unique(Pheno_Amt[[i]][3]$Kit))# take the third list from each respective amount selected from norm_miR names - the third is the kit - so for each kit in the list of kits for a given amount...
  Can_split_norm_Amt[[i]][[kit]] <-data.frame(Can_norm_miR[[i]][which(Pheno_Amt[[i]][3] == kit)]) # take only the values that correspond to that kit for that amount
}
#str(split_norm_Amt)
```




###Filter the data across triplicates for given kit at a given amount
```{r}
###genefilter
library(genefilter)

poverafun <- genefilter::pOverA(p = 1, A = 10)#at least 100 normalized reads in all samples of the set... 
ffun <- filterfun(poverafun)
genefilt_fun<- function(x){genefilter(x, ffun)}

thresh <-list()
<<<<<<< HEAD
for(amt in names(split_norm_Amt)){
thresh[[amt]]<-lapply(split_norm_Amt[[amt]], genefilt_fun)}

Can_thresh <-list()
for(amt in names(Can_split_norm_Amt)){
Can_thresh[[amt]]<-lapply(Can_split_norm_Amt[[amt]], genefilt_fun)}
=======
for(amt in names(split_norm_Amt))
thresh[[amt]]<-lapply(split_norm_Amt[[amt]], genefilt_fun)

Can_thresh <-list()
for(amt in names(Can_split_norm_Amt))
Can_thresh[[amt]]<-lapply(Can_split_norm_Amt[[amt]], genefilt_fun)
>>>>>>> b7bb0ed04bcb3658c273201b6af02e8a95fddf50


test <-split_norm_Amt$starting_amt_1000$Clontech[thresh$starting_amt_1000$Clontech,]

split_amt_thresh <-list()
for(amt in names(split_norm_Amt)){
for(kit in names(split_norm_Amt[[amt]])){
 split_amt_thresh[[amt]][[kit]]<- split_norm_Amt[[amt]][[kit]][thresh[[amt]][[kit]],]}
}

Can_split_amt_thresh <-list()
for(amt in names(Can_split_norm_Amt)){
for(kit in names(Can_split_norm_Amt[[amt]])){
 Can_split_amt_thresh[[amt]][[kit]]<- Can_split_norm_Amt[[amt]][[kit]][Can_thresh[[amt]][[kit]],]}
}
```

#detected miRNAs
```{r}
head(iso_anno[rownames(split_amt_thresh$starting_amt_100$Clontech),])
get_miRNAs <- function(x) {rownames(as.data.frame(x))}
miRNA_det_100<-lapply(split_amt_thresh$starting_amt_100,get_miRNAs)
lengths<-lapply(miRNA_det_100, length)
lengths<- paste0(lengths, "\n")
names(miRNA_det_100) <-paste0(names(miRNA_det_100), "\n")
names(miRNA_det_100) <-paste0(names(miRNA_det_100), lengths)

miRNA_det_250<-lapply(split_amt_thresh$starting_amt_250,get_miRNAs)
lengths<-lapply(miRNA_det_250, length)
names(miRNA_det_250) <-paste0(names(miRNA_det_250), "\n")
names(miRNA_det_250) <-paste0(names(miRNA_det_250), lengths)

miRNA_det_500<-lapply(split_amt_thresh$starting_amt_500,get_miRNAs)
lengths<-lapply(miRNA_det_500, length)
names(miRNA_det_500) <-paste0(names(miRNA_det_500), "\n")
names(miRNA_det_500) <-paste0(names(miRNA_det_500), lengths)

miRNA_det_1000<-lapply(split_amt_thresh$starting_amt_1000,get_miRNAs)
lengths<-lapply(miRNA_det_1000, length)
names(miRNA_det_1000) <-paste0(names(miRNA_det_1000), "\n")
names(miRNA_det_1000) <-paste0(names(miRNA_det_1000), lengths)

miRNA_det_1500<-lapply(split_amt_thresh$starting_amt_1500,get_miRNAs)
lengths<-lapply(miRNA_det_1500, length)
names(miRNA_det_1500) <-paste0(names(miRNA_det_1500), "\n")
names(miRNA_det_1500) <-paste0(names(miRNA_det_1500), lengths)

miRNA_det_2000<-lapply(split_amt_thresh$starting_amt_2000,get_miRNAs)
lengths<-lapply(miRNA_det_2000, length)
names(miRNA_det_2000) <-paste0(names(miRNA_det_2000), "\n")
names(miRNA_det_2000) <-paste0(names(miRNA_det_2000), lengths)
```

#detected miRNAs Can
```{r}
Can_miRNA_det_100<-lapply(Can_split_amt_thresh$starting_amt_100,get_miRNAs)
lengths<-lapply(Can_miRNA_det_100, length)
lengths<- paste0(lengths, "\n")
names(Can_miRNA_det_100) <-paste0(names(Can_miRNA_det_100), "\n")
names(Can_miRNA_det_100) <-paste0(names(Can_miRNA_det_100), lengths)

Can_miRNA_det_250<-lapply(Can_split_amt_thresh$starting_amt_250,get_miRNAs)
lengths<-lapply(Can_miRNA_det_250, length)
names(Can_miRNA_det_250) <-paste0(names(Can_miRNA_det_250), "\n")
names(Can_miRNA_det_250) <-paste0(names(Can_miRNA_det_250), lengths)

Can_miRNA_det_500<-lapply(Can_split_amt_thresh$starting_amt_500,get_miRNAs)
lengths<-lapply(Can_miRNA_det_500, length)
names(Can_miRNA_det_500) <-paste0(names(Can_miRNA_det_500), "\n")
names(Can_miRNA_det_500) <-paste0(names(Can_miRNA_det_500), lengths)

Can_miRNA_det_1000<-lapply(Can_split_amt_thresh$starting_amt_1000,get_miRNAs)
lengths<-lapply(Can_miRNA_det_1000, length)
names(Can_miRNA_det_1000) <-paste0(names(Can_miRNA_det_1000), "\n")
names(Can_miRNA_det_1000) <-paste0(names(Can_miRNA_det_1000), lengths)

Can_miRNA_det_1500<-lapply(Can_split_amt_thresh$starting_amt_1500,get_miRNAs)
lengths<-lapply(Can_miRNA_det_1500, length)
names(Can_miRNA_det_1500) <-paste0(names(Can_miRNA_det_1500), "\n")
names(Can_miRNA_det_1500) <-paste0(names(Can_miRNA_det_1500), lengths)

Can_miRNA_det_2000<-lapply(Can_split_amt_thresh$starting_amt_2000,get_miRNAs)
lengths<-lapply(Can_miRNA_det_2000, length)
names(Can_miRNA_det_2000) <-paste0(names(Can_miRNA_det_2000), "\n")
names(Can_miRNA_det_2000) <-paste0(names(Can_miRNA_det_2000), lengths)
```

VennDiagram
```{r}
library(VennDiagram)
gg_color_hue <- function(n) {
  hues = seq(15, 375, length = n + 1)
  hcl(h = hues, l = 65, c = 100)[1:n]
}

n = 5
cols = gg_color_hue(n)
cols <-c(cols[1], cols[3:5])

vp_100 <- venn.diagram(miRNA_det_100, fill = c(cols), alpha = 0.5, filename = NULL, margin = 0.2, cat.dist = c(.25,.25,.15, .15))
vp_250 <- venn.diagram(miRNA_det_250, fill = c(cols), alpha = 0.5, filename = NULL, margin = 0.2, cat.dist = c(.25,.25,.15, .15))
vp_500 <- venn.diagram(miRNA_det_500, fill = c(cols), alpha = 0.5, filename = NULL, margin = 0.2, cat.dist = c(.25,.25,.15, .15))
vp_1000 <- venn.diagram(miRNA_det_500, fill = c(cols), alpha = 0.5, filename = NULL, margin = 0.2, cat.dist = c(.25,.25,.15, .15))
vp_1500 <- venn.diagram(miRNA_det_1500, fill = c(cols), alpha = 0.5, filename = NULL, margin = 0.2, cat.dist = c(.25,.25,.15, .15))
vp_2000 <- venn.diagram(miRNA_det_2000, fill = c(cols), alpha = 0.5, filename = NULL, margin = 0.2, cat.dist = c(.25,.25,.15, .15))


vp_Can100 <- venn.diagram(Can_miRNA_det_100, fill = c(cols), alpha = 0.5, filename = NULL, margin = 0.2, cat.dist = c(.25,.25,.15, .15))
vp_Can250 <- venn.diagram(Can_miRNA_det_250, fill = c(cols), alpha = 0.5, filename = NULL, margin = 0.2, cat.dist = c(.25,.25,.15, .15))
vp_Can500 <- venn.diagram(Can_miRNA_det_500, fill = c(cols), alpha = 0.5, filename = NULL, margin = 0.2, cat.dist = c(.25,.25,.15, .15))
vp_Can1000 <- venn.diagram(Can_miRNA_det_500, fill = c(cols), alpha = 0.5, filename = NULL, margin = 0.2, cat.dist = c(.25,.25,.15, .15))
vp_Can1500 <- venn.diagram(Can_miRNA_det_1500, fill = c(cols), alpha = 0.5, filename = NULL, margin = 0.2, cat.dist = c(.25,.25,.15, .15))
vp_Can2000 <- venn.diagram(Can_miRNA_det_2000, fill = c(cols), alpha = 0.5, filename = NULL, margin = 0.2, cat.dist = c(.25,.25,.15, .15))


```

grid.draw(vp_1000);


OLDER
```{r}
split_norm_Amt <- list() 
for(i in names(norm_miR)) {
  for(kit in unique(Pheno_Amt[[i]][3]))# take the third list from each respective amount selected from norm_miR names - the third is the kit - so for each kit in the list of kits for a given amount...
  split_norm_Amt[[i]][[kit]] <-data.frame(norm_miR[[i]][which(Pheno_Amt[[i]][3] == kit)]) # take only the values that correspond to that kit for that amount
}


library(genefilter)

poverafun <- genefilter::pOverA(p = 1, A = 10)#at least 100 normalized reads in all samples of the set... 
ffun <- filterfun(poverafun)
genefilt_fun<- function(x){genefilter(x, ffun)}

thresh <-list()
for(amt in names(split_norm_Amt)){
thresh[[amt]]<-lapply(split_norm_Amt[[amt]], genefilt_fun)}

test <-split_norm_Amt$starting_amt_1000$Clontech[thresh$starting_amt_1000$Clontech,]

split_amt_thresh <-list()
for(amt in names(split_norm_Amt)){
for(kit in names(split_norm_Amt[[amt]])){
 split_amt_thresh[[amt]][[kit]]<- split_norm_Amt[[amt]][[kit]][thresh[[amt]][[kit]],]}
}


#detected miRNAs

head(annotation[rownames(split_amt_thresh$starting_amt_100$Clontech),])
get_miRNAs <- function(x) {rownames(as.data.frame(x))}
miRNA_det_100<-lapply(split_amt_thresh$starting_amt_100,get_miRNAs)
lengths<-lapply(miRNA_det_100, length)
lengths<- paste0(lengths, "\n")
names(miRNA_det_100) <-paste0(names(miRNA_det_100), "\n")
names(miRNA_det_100) <-paste0(names(miRNA_det_100), lengths)

miRNA_det_250<-lapply(split_amt_thresh$starting_amt_250,get_miRNAs)
lengths<-lapply(miRNA_det_250, length)
names(miRNA_det_250) <-paste0(names(miRNA_det_250), "\n")
names(miRNA_det_250) <-paste0(names(miRNA_det_250), lengths)

miRNA_det_500<-lapply(split_amt_thresh$starting_amt_500,get_miRNAs)
lengths<-lapply(miRNA_det_500, length)
names(miRNA_det_500) <-paste0(names(miRNA_det_500), "\n")
names(miRNA_det_500) <-paste0(names(miRNA_det_500), lengths)

miRNA_det_1000<-lapply(split_amt_thresh$starting_amt_1000,get_miRNAs)
lengths<-lapply(miRNA_det_1000, length)
names(miRNA_det_1000) <-paste0(names(miRNA_det_1000), "\n")
names(miRNA_det_1000) <-paste0(names(miRNA_det_1000), lengths)

miRNA_det_1500<-lapply(split_amt_thresh$starting_amt_1500,get_miRNAs)
lengths<-lapply(miRNA_det_1500, length)
names(miRNA_det_1500) <-paste0(names(miRNA_det_1500), "\n")
names(miRNA_det_1500) <-paste0(names(miRNA_det_1500), lengths)

miRNA_det_2000<-lapply(split_amt_thresh$starting_amt_2000,get_miRNAs)
lengths<-lapply(miRNA_det_2000, length)
names(miRNA_det_2000) <-paste0(names(miRNA_det_2000), "\n")
names(miRNA_det_2000) <-paste0(names(miRNA_det_2000), lengths)

library(VennDiagram)
gg_color_hue <- function(n) {
  hues = seq(15, 375, length = n + 1)
  hcl(h = hues, l = 65, c = 100)[1:n]
}

n = 5
cols = gg_color_hue(n)
cols <-c(cols[1], cols[3:5])

vp_100 <- venn.diagram(miRNA_det_100, fill = c(cols), alpha = 0.5, filename = NULL, margin = 0.2, cat.dist = c(.25,.25,.15, .15))
vp_250 <- venn.diagram(miRNA_det_250, fill = c(cols), alpha = 0.5, filename = NULL, margin = 0.2, cat.dist = c(.25,.25,.15, .15))
vp_500 <- venn.diagram(miRNA_det_500, fill = c(cols), alpha = 0.5, filename = NULL, margin = 0.2, cat.dist = c(.25,.25,.15, .15))

cols = gg_color_hue(n)
vp_1000 <- venn.diagram(miRNA_det_1000, fill = c(cols), alpha = 0.5, filename = NULL, margin = 0.2, cat.dist = c(.25,.25,.25, .25, .35))

cols = gg_color_hue(n)
cols <-c(cols[1:2], cols[4:5])
vp_1500 <- venn.diagram(miRNA_det_1500, fill = c(cols), alpha = 0.5, filename = NULL, margin = 0.2, cat.dist = c(.25,.25,.15, .15))
vp_2000 <- venn.diagram(miRNA_det_2000, fill = c(cols), alpha = 0.5, filename = NULL, margin = 0.2, cat.dist = c(.25,.25,.15, .15))

```
grid.draw(vp_1000);




=======
>>>>>>> b7bb0ed04bcb3658c273201b6af02e8a95fddf50
```{r, eval  = FALSE}

###Will output two additional files, isomirs.csv and isomirs.samples.csv. The first file has the entropy of each isomir as compared with their canonical miRNAs - % of time noncanonical - higher number means less canonical more isomirs. The second file contains the entropy of each miRNA across all isomirs and determines the % of miRNA reads that are canonical. This is done by dividing the sum of all non-edited, but length variable miRNA reads against the sum of these reads plus all isomiR (RNA-edited) reads. This can be used to flag miRNAs that are predominately ####non-canonical isomiRs and may represent sequencing errors. For example, if a miRNA is only 5% canonical, that would be worrisome and suggest a possible misidentification.

#I believe the isomirs.csv file contains one column of entropy - the one called entropy for each isomiRNA (as compared with the canonical) and then RPMs... as the values are not whole numbers... then isomirs.samples.csv contains the % of the time that a miRNA is canonical and the entropy for each isomiRNA relatve to other isomiRs for each sample pr maybe its the percent of the time that an isomiRNA is a canonical type of isomir???meaning just length variable??


# I think Entropy in isomirs.samples.csv (but this maybe the percent canonical isomiR type) = sum of all length isomir reads / sum of all types of isomir (length and RNA-edited) reads - thus if too low this is bad... seems to range to about 50% or .5

#sounds like low entropy in the isomirs.samples.csv is bad - means mostly edited-- could be sequencing error - check canonical percentage too if it is low then probably sequencing error or maybe this meens the 

iso_RPM<-read.table(here("isomiR_data_extended/isomirs.csv"), header = T, sep = ",", row.names=NULL)
iso_RPM <-iso_RPM[-grep("fq.", colnames(iso_RPM))]# to remove extra files.....

isosamples<- read.table(here("isomiR_data_extended/isomirs.samples.csv"), header = T, sep = ",", row.names=NULL)
isosamples <-isosamples[-grep("RPM.", colnames(isosamples))]# to remove extra files.....

<<<<<<< HEAD
miR_counts <- read.table(here("isomiR_data/miR.Counts.csv"),header = T, sep = ",")
=======
miR_counts <- read.table(here("isomiR_data_extended/miR.Counts.csv"),header = T, sep = ",")
>>>>>>> b7bb0ed04bcb3658c273201b6af02e8a95fddf50
miR_counts <-miR_counts[-grep("fq.", colnames(miR_counts))]# to remove extra files.....

#fixing the columns
iso_data<-iso_RPM[1:(length(colnames(iso_RPM))-1)]
colnames(iso_data)<-colnames(iso_RPM)[2:(length(colnames(iso_RPM)))]
iso_RPM2 <- iso_data[,4:length(colnames(iso_data))-1]
iso_RPM2_anno<-iso_data[1:2]

#fixing the colnames
iso_samp<-isosamples[1:(length(colnames(isosamples))-1)]
colnames(iso_samp)<-colnames(isosamples)[2:length(colnames(isosamples))]
#getting just the raw info
index<-grep("RPM", colnames(iso_samp))
iso_samp_filt<-iso_samp[-index]
rownames(iso_samp_filt)<- iso_samp$miRNA
iso_samp_filt<-iso_samp_filt[-1]

topIsomiR_entropy <-  iso_samp_filt[grep("isomir", colnames(iso_samp_filt))]
Canonical <- iso_samp_filt[grep("Canonical", colnames(iso_samp_filt))]


###convert to raw counts... use miR_counts to get total miRNA mapped number - so the miRcounts I believe includes all sequences that allign - isomir and canonical
Total<-(miR_counts[1,])[-1] #remove miRNA column
rep.row<-function(x,n){
   matrix(rep(x,each=n),nrow=n)
}
dim(iso_RPM2)
Totalmatrix<-rep.row((Total/1000000), 4430447)#width of isoRPM2

iso_Raw<- (iso_RPM2)*(as.numeric(Totalmatrix))
#save(iso_Raw, file = here("isomiR_data_extended/iso_Raw.rda"))
iso_anno <-iso_RPM2_anno
<<<<<<< HEAD
#save(iso_anno, file = here("isomiR_data_extended/iso_anno.rda"))
=======
save(iso_anno, file = here("isomiR_data_extended/iso_anno.rda"))
>>>>>>> b7bb0ed04bcb3658c273201b6af02e8a95fddf50

##########

#save(Canonical, file = here("isomiR_data_extended/Canonicalpercent.rda"))
#save(topIsomiR_entropy, file = here("isomiR_data_extended/topIsomiR_entropy.rda"))

```


#####start here for faster analysis

```{r}
load(here("isomiR_data_extended/iso_Raw.rda"))
load(here("isomiR_data_extended/iso_anno.rda"))
Pheno<- read.table(here("IsomiR_data/IsoPheno.txt"), header = T)
identical(colnames(iso_Raw), as.character(Pheno$File))
miR_counts <- read.table(here("isomiR_data_extended/miR.Counts.csv"),header = T, sep = ",")
miR_counts <-miR_counts[-grep("fq.", colnames(miR_counts))]# to remove extra files.....
miR_counts <-miR_counts[-grep("acc", colnames(miR_counts))]# to remove second batch of 1000ng files.....
Total_counts <-miR_counts[1,]
miR_counts <-miR_counts[-1,]
miR_counts <-miR_counts[-1]
#remove second batch of 1000ng starting input
iso_Raw <- iso_Raw[-grep("acc", colnames(iso_Raw))]
Pheno <- Pheno [-grep("acc", Pheno$File),]
```


### comparison of error for each kit for given starting amount
##Split the data
```{r}

Pheno$startingAmt<-paste0("starting_amt_", Pheno$startingAmt)
###split the data by starting Amount
split_startingAmt <- list() 
for(i in Pheno$startingAmt) { 
  split_startingAmt[[i]] <- data.frame(iso_Raw[which(Pheno$startingAmt==i)])
}
###split the pheno by starting Amount
Pheno_Amt <- list() 
for(i in Pheno$startingAmt) { 
  Pheno_Amt[[i]] <- data.frame(Pheno[which(Pheno$startingAmt==i),])
}

Can_split_startingAmt <- list() 
for(i in Pheno$startingAmt) { 
  Can_split_startingAmt[[i]] <- data.frame(miR_counts[which(Pheno$startingAmt==i)])
}
```
###TMM Normalization

Normalization by kit for each starting amount - to allow tests to compare kits at a given starting amt

Later will do normalization by starting amount for each kit  individually to compare how consistent the data is between starting amounts for each kit
```{r, eval= TRUE, echo =FALSE}
#library(tweeDEseq)
#miR_1000_TMM<-data.frame(normalizeCounts(miR_1000_raw)
#dim(norm_miR_1000)
#or
library(edgeR)

norm_miR <-list()
for(i in unique(Pheno$startingAmt)){
d<-DGEList(counts = split_startingAmt[[i]], group = Pheno$Kit[which(Pheno$startingAmt==i)])
miR_TMM_edgeR_factors <-calcNormFactors(d, method = "TMM")
TMM <-estimateCommonDisp(miR_TMM_edgeR_factors)
norm_miR[[i]] <-data.frame(TMM$pseudo.counts)
}

#str(norm_miR)

Can_norm_miR <-list()
for(i in unique(Pheno$startingAmt)){
d<-DGEList(counts =Can_split_startingAmt[[i]], group = Pheno$Kit[which(Pheno$startingAmt==i)])
miR_TMM_edgeR_factors <-calcNormFactors(d, method = "TMM")
TMM <-estimateCommonDisp(miR_TMM_edgeR_factors)
Can_norm_miR[[i]] <-data.frame(TMM$pseudo.counts)
}

```

Now split normalized data by kit for each amount
```{r}

split_norm_Amt <- list() 
for(i in names(norm_miR)) {
  for(kit in unique(Pheno_Amt[[i]][3]$Kit))# take the third list from each respective amount selected from norm_miR names - the third is the kit - so for each kit in the list of kits for a given amount...
  split_norm_Amt[[i]][[kit]] <-data.frame(norm_miR[[i]][which(Pheno_Amt[[i]][3] == kit)]) # take only the values that correspond to that kit for that amount
}

Can_split_norm_Amt <- list() 
for(i in names(Can_norm_miR)) {
  for(kit in unique(Pheno_Amt[[i]][3]$Kit))# take the third list from each respective amount selected from norm_miR names - the third is the kit - so for each kit in the list of kits for a given amount...
  Can_split_norm_Amt[[i]][[kit]] <-data.frame(Can_norm_miR[[i]][which(Pheno_Amt[[i]][3] == kit)]) # take only the values that correspond to that kit for that amount
}
#str(split_norm_Amt)
```




###Filter the data across triplicates for given kit at a given amount
```{r}
###genefilter
library(genefilter)

poverafun <- genefilter::pOverA(p = 1, A = 10)#at least 100 normalized reads in all samples of the set... 
ffun <- filterfun(poverafun)
genefilt_fun<- function(x){genefilter(x, ffun)}

thresh <-list()
<<<<<<< HEAD
for(amt in names(split_norm_Amt)){
thresh[[amt]]<-lapply(split_norm_Amt[[amt]], genefilt_fun)}

Can_thresh <-list()
for(amt in names(Can_split_norm_Amt)){
Can_thresh[[amt]]<-lapply(Can_split_norm_Amt[[amt]], genefilt_fun)}
=======
for(amt in names(split_norm_Amt))
thresh[[amt]]<-lapply(split_norm_Amt[[amt]], genefilt_fun)

Can_thresh <-list()
for(amt in names(Can_split_norm_Amt))
Can_thresh[[amt]]<-lapply(Can_split_norm_Amt[[amt]], genefilt_fun)
>>>>>>> b7bb0ed04bcb3658c273201b6af02e8a95fddf50


test <-split_norm_Amt$starting_amt_1000$Clontech[thresh$starting_amt_1000$Clontech,]

split_amt_thresh <-list()
for(amt in names(split_norm_Amt)){
for(kit in names(split_norm_Amt[[amt]])){
 split_amt_thresh[[amt]][[kit]]<- split_norm_Amt[[amt]][[kit]][thresh[[amt]][[kit]],]}
}

Can_split_amt_thresh <-list()
for(amt in names(Can_split_norm_Amt)){
for(kit in names(Can_split_norm_Amt[[amt]])){
 Can_split_amt_thresh[[amt]][[kit]]<- Can_split_norm_Amt[[amt]][[kit]][Can_thresh[[amt]][[kit]],]}
}
```

#detected miRNAs
```{r}
head(iso_anno[rownames(split_amt_thresh$starting_amt_100$Clontech),])
get_miRNAs <- function(x) {rownames(as.data.frame(x))}
miRNA_det_100<-lapply(split_amt_thresh$starting_amt_100,get_miRNAs)
lengths<-lapply(miRNA_det_100, length)
lengths<- paste0(lengths, "\n")
names(miRNA_det_100) <-paste0(names(miRNA_det_100), "\n")
names(miRNA_det_100) <-paste0(names(miRNA_det_100), lengths)

miRNA_det_250<-lapply(split_amt_thresh$starting_amt_250,get_miRNAs)
lengths<-lapply(miRNA_det_250, length)
names(miRNA_det_250) <-paste0(names(miRNA_det_250), "\n")
names(miRNA_det_250) <-paste0(names(miRNA_det_250), lengths)

miRNA_det_500<-lapply(split_amt_thresh$starting_amt_500,get_miRNAs)
lengths<-lapply(miRNA_det_500, length)
names(miRNA_det_500) <-paste0(names(miRNA_det_500), "\n")
names(miRNA_det_500) <-paste0(names(miRNA_det_500), lengths)

miRNA_det_1000<-lapply(split_amt_thresh$starting_amt_1000,get_miRNAs)
lengths<-lapply(miRNA_det_1000, length)
names(miRNA_det_1000) <-paste0(names(miRNA_det_1000), "\n")
names(miRNA_det_1000) <-paste0(names(miRNA_det_1000), lengths)

miRNA_det_1500<-lapply(split_amt_thresh$starting_amt_1500,get_miRNAs)
lengths<-lapply(miRNA_det_1500, length)
names(miRNA_det_1500) <-paste0(names(miRNA_det_1500), "\n")
names(miRNA_det_1500) <-paste0(names(miRNA_det_1500), lengths)

miRNA_det_2000<-lapply(split_amt_thresh$starting_amt_2000,get_miRNAs)
lengths<-lapply(miRNA_det_2000, length)
names(miRNA_det_2000) <-paste0(names(miRNA_det_2000), "\n")
names(miRNA_det_2000) <-paste0(names(miRNA_det_2000), lengths)
```

#detected miRNAs Can
```{r}
Can_miRNA_det_100<-lapply(Can_split_amt_thresh$starting_amt_100,get_miRNAs)
lengths<-lapply(Can_miRNA_det_100, length)
lengths<- paste0(lengths, "\n")
names(Can_miRNA_det_100) <-paste0(names(Can_miRNA_det_100), "\n")
names(Can_miRNA_det_100) <-paste0(names(Can_miRNA_det_100), lengths)

Can_miRNA_det_250<-lapply(Can_split_amt_thresh$starting_amt_250,get_miRNAs)
lengths<-lapply(Can_miRNA_det_250, length)
names(Can_miRNA_det_250) <-paste0(names(Can_miRNA_det_250), "\n")
names(Can_miRNA_det_250) <-paste0(names(Can_miRNA_det_250), lengths)

Can_miRNA_det_500<-lapply(Can_split_amt_thresh$starting_amt_500,get_miRNAs)
lengths<-lapply(Can_miRNA_det_500, length)
names(Can_miRNA_det_500) <-paste0(names(Can_miRNA_det_500), "\n")
names(Can_miRNA_det_500) <-paste0(names(Can_miRNA_det_500), lengths)

Can_miRNA_det_1000<-lapply(Can_split_amt_thresh$starting_amt_1000,get_miRNAs)
lengths<-lapply(Can_miRNA_det_1000, length)
names(Can_miRNA_det_1000) <-paste0(names(Can_miRNA_det_1000), "\n")
names(Can_miRNA_det_1000) <-paste0(names(Can_miRNA_det_1000), lengths)

Can_miRNA_det_1500<-lapply(Can_split_amt_thresh$starting_amt_1500,get_miRNAs)
lengths<-lapply(Can_miRNA_det_1500, length)
names(Can_miRNA_det_1500) <-paste0(names(Can_miRNA_det_1500), "\n")
names(Can_miRNA_det_1500) <-paste0(names(Can_miRNA_det_1500), lengths)

Can_miRNA_det_2000<-lapply(Can_split_amt_thresh$starting_amt_2000,get_miRNAs)
lengths<-lapply(Can_miRNA_det_2000, length)
names(Can_miRNA_det_2000) <-paste0(names(Can_miRNA_det_2000), "\n")
names(Can_miRNA_det_2000) <-paste0(names(Can_miRNA_det_2000), lengths)
```

VennDiagram
```{r}
library(VennDiagram)
gg_color_hue <- function(n) {
  hues = seq(15, 375, length = n + 1)
  hcl(h = hues, l = 65, c = 100)[1:n]
}

n = 5
cols = gg_color_hue(n)
cols <-c(cols[1], cols[3:5])

vp_100 <- venn.diagram(miRNA_det_100, fill = c(cols), alpha = 0.5, filename = NULL, margin = 0.2, cat.dist = c(.25,.25,.15, .15))
vp_250 <- venn.diagram(miRNA_det_250, fill = c(cols), alpha = 0.5, filename = NULL, margin = 0.2, cat.dist = c(.25,.25,.15, .15))
vp_500 <- venn.diagram(miRNA_det_500, fill = c(cols), alpha = 0.5, filename = NULL, margin = 0.2, cat.dist = c(.25,.25,.15, .15))
vp_1000 <- venn.diagram(miRNA_det_500, fill = c(cols), alpha = 0.5, filename = NULL, margin = 0.2, cat.dist = c(.25,.25,.15, .15))
vp_1500 <- venn.diagram(miRNA_det_1500, fill = c(cols), alpha = 0.5, filename = NULL, margin = 0.2, cat.dist = c(.25,.25,.15, .15))
vp_2000 <- venn.diagram(miRNA_det_2000, fill = c(cols), alpha = 0.5, filename = NULL, margin = 0.2, cat.dist = c(.25,.25,.15, .15))


vp_Can100 <- venn.diagram(Can_miRNA_det_100, fill = c(cols), alpha = 0.5, filename = NULL, margin = 0.2, cat.dist = c(.25,.25,.15, .15))
vp_Can250 <- venn.diagram(Can_miRNA_det_250, fill = c(cols), alpha = 0.5, filename = NULL, margin = 0.2, cat.dist = c(.25,.25,.15, .15))
vp_Can500 <- venn.diagram(Can_miRNA_det_500, fill = c(cols), alpha = 0.5, filename = NULL, margin = 0.2, cat.dist = c(.25,.25,.15, .15))
vp_Can1000 <- venn.diagram(Can_miRNA_det_500, fill = c(cols), alpha = 0.5, filename = NULL, margin = 0.2, cat.dist = c(.25,.25,.15, .15))
vp_Can1500 <- venn.diagram(Can_miRNA_det_1500, fill = c(cols), alpha = 0.5, filename = NULL, margin = 0.2, cat.dist = c(.25,.25,.15, .15))
vp_Can2000 <- venn.diagram(Can_miRNA_det_2000, fill = c(cols), alpha = 0.5, filename = NULL, margin = 0.2, cat.dist = c(.25,.25,.15, .15))


```

grid.draw(vp_1000);


Split total miRNA reads

```{r}

Total_counts<-Total_counts[-1]
###split the total counts by amount
split_total<- list() 
for(i in Pheno$TriplicateGroup) { 
 split_total[[i]] <- rowMeans(Total_counts[which(Pheno$TriplicateGroup==i)])
}
split_total<-data.frame(split_total)
split_total_miRNA<-split_total
boxplot(split_total_miRNA)

```

report stats
```{r}
library(XML)
<<<<<<< HEAD
report_url<-here("IsomiR_data_new_incomplete/report.html")
=======
report_url<-here("isomiR_data/report.html")
>>>>>>> b7bb0ed04bcb3658c273201b6af02e8a95fddf50
urltxt <- readLines(report_url)
report<-readHTMLTable(doc = report_url, header = TRUE) #need to read every third line
report <- report [-length(report)]
report <-as.data.frame(report)
report <-report[1:9]
report <-report[seq(from =1, to = nrow(report), by = 5),]
total_reads <-as.numeric(as.character(report$NULL.Total.Input.Reads))

split_total<- list() 
for(i in Pheno$TriplicateGroup) { 
 split_total[[i]] <- mean(total_reads[which(Pheno$TriplicateGroup==i)])
}
split_total<-data.frame(split_total)
boxplot(split_total)

<<<<<<< HEAD
split_total_miRNA<- list() 
for(i in Pheno$TriplicateGroup) { 
 split_total_miRNA[[i]] <- mean(total_miRNA[which(Pheno$TriplicateGroup==i)])
}
split_total_miRNA<-data.frame(split_total_miRNA)
                        
=======

>>>>>>> b7bb0ed04bcb3658c273201b6af02e8a95fddf50
boxplot(log2(split_total))
boxplot(log2(split_total_miRNA))

total_reads_final<-t(split_total)
total_miRNA_final<-t(split_total_miRNA)
totals <-data.frame(reads =total_reads_final, miRNAreads = total_miRNA_final)
<<<<<<< HEAD
####somehow figure out how to get lengths of isomiRS so we can see if they correlate with raw read count or miRNA total count 
=======
####somehow figure out how to get lengths of isomiRS so we can see if they correlate with raw read count or miRNA total count
>>>>>>> b7bb0ed04bcb3658c273201b6af02e8a95fddf50
get_lengths <-function(x){length(rownames(x))}
lapply(split_amt_thresh$starting_amt_starting_amt_starting_amt_100, get_lengths)
split_iso<- list() 
for(i in Pheno$startingAmt) { 
  for(kit in Pheno$Kit){
 split_iso[[i]][[kit]] <- mean(split_amt_thresh[which(Pheno$startingAmt==i & Pheno$Kit == kit)])
}}
split_total<-data.frame(split_total)
boxplot(split_total)



```

























###TMM Normalization

Normalization by kit for each starting amount - to allow tests to compare kits

```{r, eval= TRUE, echo =FALSE}
library(edgeR)

norm_isomiR <-list()
d<-DGEList(counts = iso_Raw, group = Pheno$Kit)
miR_TMM_edgeR_factors <-calcNormFactors(d, method = "TMM")
TMM <-estimateCommonDisp(miR_TMM_edgeR_factors)
norm_isomiR[[i]] <-data.frame(TMM$pseudo.counts)


```

Now split normalized data by kit for each amount
```{r}

split_norm_Amt <- list() 
for(i in names(norm_miR)) {
  for(kit in unique(Pheno_Amt[[i]][3]$Kit))# take the third list from each respective amount selected from norm_miR names - the third is the kit - so for each kit in the list of kits for a given amount...
  split_norm_Amt[[i]][[kit]] <-data.frame(norm_miR[[i]][which(Pheno_Amt[[i]][3] == kit)]) # take only the values that correspond to that kit for that amount
}
#str(split_norm_Amt)
```


################Analysis starts here#########################

```{r}
library(here)
here()#should be Kit_comparison_project
#need subdirectory IsomiR_data with isomirs.csv inside
#isomiR_Counts <-read.table(here("IsomiR_data/isomirs.csv"), header = TRUE, sep = ",", row.names = NULL)
#colnames(isomiR_Counts)<-colnames(isomiR_Counts)[-(grep("row.names", colnames(isomiR_Counts)))]
#isomiR_Counts<-as.data.frame(isomiR_Counts)
#Entropy <- isomiR_Counts$Entropy
#save(isomiR_Counts, file =here("IsomiR_data/isomiR_Counts.rda"))
Pheno<- read.table(here("Pheno_repro_full_1_16_18_ns_kept.txt"), header = T)
#Counts <-isomiR_Counts[3:101]
#Counts <-Counts[-grep("fq.", colnames(Counts))]

#colnames(Counts)<-gsub("directional_dedupped|directional_deduped", "Deduped", colnames(Counts))
#colnames(Counts)<-gsub("NEXT_", "NEXTflex_", colnames(Counts))

#save(Counts, file =here("IsomiR_data/Counts.rda"))
#save(Entropy, file = here("IsomiR_data/Entropy.rda"))

Pheno<-vapply(strsplit(names(Counts),"_"), `[`, 1, FUN.VALUE=character(1))
load(here("IsomiR_data/Entropy.rda"))
load(here("IsomiR_data/Counts.rda"))
Pheno_simple <- read.table("Pheno_simple.txt", header = TRUE)

#remove 2nd batch of 1000
Counts_clean <- Counts[-grep("2", Pheno_simple$Batch),]# can't do on my laptop

```

###TMM Normalization

Normalization by kit for each starting amount - to allow tests to compare kits

```{r, eval= TRUE, echo =FALSE}
library(edgeR)

norm_isomiR <-list()
d<-DGEList(counts = Counts, group = Pheno_simple$Kit)
miR_TMM_edgeR_factors <-calcNormFactors(d, method = "TMM")
TMM <-estimateCommonDisp(miR_TMM_edgeR_factors)
norm_isomiR[[i]] <-data.frame(TMM$pseudo.counts)
}

for(i in unique(Pheno_simple$Kit)){
d<-DGEList(counts = Counts[grep(i, colnames(Counts))], group = Pheno_simple$Kit[which(Pheno_simple$Kit==i)])
miR_TMM_edgeR_factors <-calcNormFactors(d, method = "TMM")
TMM <-estimateCommonDisp(miR_TMM_edgeR_factors)
norm_isomiR[[i]] <-data.frame(TMM$pseudo.counts)
}

NEXTflex <- Counts[grep(i, colnames())]

#str(norm_isomiR)

```

Now split normalized data by kit for each amount
```{r}

split_norm_Kit <- list() 
for(i in names(norm_miR)) {
  for(kit in unique(Pheno_Amt[[i]][3]$Kit))# take the third list from each respective amount selected from norm_miR names - the third is the kit - so for each kit in the list of kits for a given amount...
  split_norm_Kit[[i]][[kit]] <-data.frame(norm_isomiR[[i]][which(Pheno_Amt[[i]][3] == kit)]) # take only the values that correspond to that kit for that amount
}
#str(split_norm_Amt)
```

results in nice format
```{r}

results<-read.csv(here("../../kit_comp_isomir_results.csv"), header = TRUE)
results <-results[1:5,]
meltedresult<-melt(results)
```
